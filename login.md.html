<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: Lowering the barrier to in-process sandboxing

# Introduction

Users expect featureful software, and features, it hardly needs
saying, come from code.  The more features, the more code to implement
them.  And the more code, the more bugs---the more _security_ bugs, in
particular.

The latest code rushed out before a marketing deadline, or old code that
hasn't been touched since the developer who wrote it retired, or a
specialized module you licensed: attackers will scour all of them for
bugs to use for exploiting your software and targeting your users.

The problem is especially acute with third-party open source
libraries.  You might care about one thing the library does, but you
ship the whole library, and bugs in any part of it can create to
security problems in your product.  (Unless you fork the library to
remove the extraneous code, but who wants to maintain a fork forever?)
Worse, hackers who find a bug in a popular library can try to deploy
it against every product that embeds the library---including yours.

Computer scientists have been thinking about software insecurity for
fifty years, and they have come up with approaches to mitigate it.
Rewrite your program (or parts of it) in a safer language!  Refuse to
ship new features and keep your program small!  Formally verify the
correctness of your software!  "Privilege separate" your system by
re-architecting it into multiple mutually-distrusting processes!  It's
fair to say that none of these approaches has solved the problem.
Insecure software is all around.

We believe that there is a practical path to improving software
security.  You can take software modules, including third-party
libraries, and _sandbox_ them to constrain what they can do---with low
programmer effort, reasonable runtime overhead, and without wholesale
rewriting or re-architecting---without even creating new OS processes.
The sandboxed module will still have bugs, but those bugs will not (in
most cases; see below) create security vulnerabilities in the
enclosing program.

Consider an image decoding library like libpng.  With sandboxing, we
can restrict this library so it has access to the image it decodes and
the bitmap it produces, _and that's it_.  Or, consider a
spell-checking library like Hunspell.  With sandboxing, we can
restrict this library to just its dictionary and the text it checks.
The application benefits from the library's features, but doesn't
inherit its security flaws.

Over the past two years we have worked with a team at Mozilla to build
a tool, called RLBox, to support sandboxing, and to migrate Firefox to
a model where many third-party libraries run sandboxed.  This new
approach is now shipping in Firefox.  Our experience suggests that
once there is sufficient tooling support that engineers can easily
sandbox libraries, they become increasingly comfortable with and
excited by the opportunities this offers.  For example, while the
initial target of our sandboxing collaboration was a third-party
font-shaping library, Graphite, now Firefox developers and security
engineers are using RLBox to sandbox both third-party libraries and
legacy Mozilla code in domains including media decoding, spell
checking, and even speech synthesis.

We believe that the opportunities extend far beyond Firefox.  After
all, secure messaging apps (e.g., Signal, WhatsApp, and iMessage),
servers and runtimes (e.g., Apache and Node.js), and enterprise tools
(e.g., Zoom, Slack, and VS Code) also rely on third party libraries
for various tasks---from media rendering, to parsing network protocols
like HTTP, image processing (e.g., to blur faces), spell checking, and
automated text completion.  With RLBox, these systems' developers are
empowered to sandbox modules and limit the damage their bugs can
cause.

Recent advances in compilers and processor architectures have made
efficient in-process isolation increasingly practical.  As it turns
out, though, keeping a module from reading or writing memory outside
its data region isn't enough.  Our initial efforts in manually
sandboxing Firefox libraries are a case in point.  Firefox had been
written under the assumptions that the libraries were trustworthy.
Even when isolated, they could return data values that would cause the
(unsandboxed) Firefox code to take unsafe actions, a scenario that
security researchers describe as a "confused deputy" attack.  We tried
to add code to manually check return values for consistency, but
repeatedly found that we had missed cases and left open avenues for
attack.

That's where RLBox comes in.  Using the C++ type system, RLBox
automatically generates the boilerplate code required for sandbox
interaction, and identifies _all_ places where the programmer will
have to add data-checking code.  With RLBox, programmers have a
framework that makes it easy to sandbox libraries (1) _securely_,
ensuring the interface between the untrusted library and the
application code is correct, and with (2) _minimal engineering
effort_, so that the cost of migrating libraries and applications to
sandboxing is not prohibitive.

In the rest of this article we describe the experience that led to
RLBox, how RLBox works and how it leverages the C++ type systems to
make sandboxing practical, and how our type-driven approach can be
used in other domains (e.g., trusted execution environments).  Then we
outline how this approach can translate to languages other than C/C++.
Finally, we end with a vision of what software development could look
like with broader first-class support for sandboxing.

Before closing, we should note that sandboxing is not a panacea.  Some
components must be _correct_, not just isolated, for the system as a
whole to be secure.  The JavaScript just-in-time compilers used by Web
browsers are a notorious example.  With RLBox, you can sandbox
everything else, and focus developer time on getting these few
critical modules right.

# The road to RLBox: library sandboxing in Firefox

Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. These libraries have been
a significant source of vulnerabilities in the browser (e.g., most of the
exploitable bugs found by recent work using symbolic execution were in
third-party libraries [[**BSE20**][BSE20]]). By retrofitting Firefox to sandbox
these libraries we can minimize the damage these vulnerabilities can inflict (e.g., like the
libvorbis bug at Pwn2Own 2018 to compromise Firefox).

When we began this project roughly two years ago, we thought the hardest part
would be adapting Google's NativeClient (NaCl), a software-based isolation
(SFI) toolkit, to sandbox libraries (NaCl is designed for sandboxing programs,
not libraries.) This turned out be the easy part. Since then, WebAssembly
toolkits---in particular the Lucet WebAssembly compiler---has made this even
easier (see [[**NGLSS19**][NGLSS19]]).

In fact, the hardest part was the _last mile_, retrofitting Firefox to account for the
now-untrusted libraries.  Firefox was written assuming libraries are trusted.
To benefit from sandboxing, we had to change its threat model to assume
libraries are untrusted, and modify the browser-library interface accordingly.
In particular, we had to sanitize all data and regulate control flow between
sandboxed libraries and the browser to prevent malicious libraries from breaking out of
their sandbox. Doing this manually was onerous and error prone.

**Sandboxing pitfalls**
To illustrate the kinds of security challenges  we encountered, consider, for
instance, refactoring the `fill_input_buffer` JPEG decoder function in Firefox.
This function is called by the libjpeg library whenever it needs more bytes
from Firefox. Additionally, Firefox must save the currently unused input bytes
held by libjpeg to an internal back buffer and resend this libjpeg along with
additional input.

```cpp
 1: void fill_input_buffer (j_decompress_ptr jd) {
 2:   struct jpeg_source_mgr* src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data;
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte, src->bytes_in_buffer);
18:   ...
19: }
````

When sandboxing libjpeg, we need to refactor this code to account for the
now-untrusted library boundary. Among other things, we must:

- Sanitize `jd`, otherwise the read of `jd->src` on line 2 becomes an
  arbitrary-read gadget.
- Sanitize `src`, otherwise the write to `src->next_input_byte` on line 5
  becomes an arbitrary-write gadget and the `memmove()` on line 16 becomes an
  arbitrary read.
- Sanitize `decoder` to ensure it points to a valid Firefox `nsJPEGDecoder`
  object, otherwise invoking a virtual method on it will hijack control flow.
- Sanitize the nested pointer `mInfo.err` on line 10 prior to dereferencing.
- Sanitize the pointer `decoder->mBackBuffer + decoder->mBackBufferLen` used on
  the destination address to `memmove()` on line 16.
- Swizzle pointers like `mInfo.err` and `decoder->mBackBuffer`, i.e., translate
  the pointers to account for the potentially different machine model of the
  sandbox. Both NaCl and WebAssembly have different pointer representations.
- Ensure that multiple threads can't invoke the callback on the same image,
  otherwise we have data race that result in a use-after-free vulnerability.

Missing any of these checks---and these are only a subset of the kinds of
checks we identified in [[**NDG+20**][NDG+20]]---allows a compromised library
to carry out _confused deputy_ attacks, i.e., abuse the application code and
its privilege to essentially break out of the sandbox.  Unfortunately, getting
all the right checks in all the right places for the hundreds of Firefox
functions that interact with libjpeg is hard. Indeed, while migrating Firefox
to this model we made many mistakes---overlooking attack vectors and
discovering many bugs only after building RLBox to help detect them.

**Engineering effort**
Even if we got all the checks right, the upfront engineering effort
of modifying the browser to sandbox each library this way is huge: We have to
retrofit all library calls, adjust data structures to account for machine model
differences between the application and sandbox (a common issue with SFI
toolchains), marshal data to and from the sandbox, etc. Only then can we run
tests to ensure our retrofitting didn't break the browser.  Finally, since
Firefox runs on many platforms---including platforms not yet supported by SFI
toolkits like NaCl and Wasm---we have to do this alongside the existing code
that use the library unsandboxed, using the C preprocessor to select between
the old code and the new code. We tried this approach. But the patches become
so complicated and unwieldy that we couldn't image anybody maintaining this code,
so we built RLBox and started anew.

# How sandboxing changes the way we build software

We know an enormous amount code in used today is written in unsafe languages
i.e.~C/C++, a fact that we believe is unlikely to change for the forseable
future. Trying to hold all the C/C++ code in our systems to a high security
standard is not reasonable, it hasn't worked and is not going to work.

Thus, in spite of the admonitions of security researchers. Real developers
everywhere are daily faced with difficult choices vis-a-vis security, do I
totally trust this third-party library to implement this feature, do I totally
trust this legacy code, or code by another team,  or even my own code to
implement this feature. Or do I forgoe this feature. Of course, if you give
people choice of assurance or functionality they will almost always choose the
later.

Sandboxing offers the potential to give developers another options. Developers
can instead choose wether code belongs in the trusted kernel of their
application, or instead should be run in a less privileged sandbox, where the
effects of a compromise can be largely mitigated.

Once the option run code in a less privileged sandbox is available, this takes
takes enormous pressure off developers.

XXX tie this back to mozilla example
XXX maybe throw in Qualcom example.



<!--

- Why third party code is sketchy - every time you add a feature pulling more
stuff into your tcb.

-hard choice: do -Trying to hold C/C++ to a high security standard is not reasonable, it hasn't
worked and is not going to work, so we need to do something else.

-How do we build secure systems with average programmers. Even greater programmers
have limitations.

-legacy code in our code base
-long tail of libraries that we depend on that won't be maintained or audited.
- Memory safety is a real bad thing.
- Your developers write code that should be sandboxed also.
- You don't want to either have to write high assurance code
- You don't want to rewrite your code in Rust.
- You don't want to write your code in Rust, C/C++ is what your team/company/project/industry
  does. 
-There will be C/C++, memory safety is a big problem, this is cheaper than 
- Samsung example
-->


# The RLBox framework

RLBox is a C++ library designed to make it easier for developers to retrofit
application to securely use sandboxed libraries.  RLBox does this by making
data and control flow at the application-sandbox boundary explicit---at the
type level--and by providing APIs to both mediate these flows and enforce
security checks across the trust boundary.

RLBox mediates data flow using _tainted types_---type wrappers used to
demarcate data originating from the sandbox.  We use tainted values to ensure
that application code cannot use sandboxed data unsafely.  For example, while
application code can add two `tainted<int>`s (to produce another
`tainted<int>`), it cannot branch on such values or use them as indexes into an
array. Instead, the application must validate tainted values before it can use
them.

RLBox mediates control flow by providing APIs for invoking sandboxed functions,
registering host functions as callbacks---to allow the sandbox to call into the
application---and more generally exchange data between the sandbox and
application.  For example, the application must use `sandbox_invoke(sbx_fn,
args...)` to invoke functions in the sandbox; sandboxed functions cannot be
called directly.  Similarly, sandboxed code cannot call into the application
arbitrarily; instead, the application must register callback functions using the
`sandbox_callback(app_fn)` API. These APIs are also key to data flow safety:
They impose a strict tainted type discipline, requiring all return values of
sandboxed functions and all callback arguments to be tainted.

This tainted type-driven approach addresses the challenges we outlined above:

- **Security:** RLBox eliminates most traps and pitfalls by turning unsafe
  control- and data-flows into type errors and, where possible, by performing
  automatic security checks.  Concretely, RLBox automatically sanitizes
  sandbox-supplied (tainted) pointers to ensure they point sandbox memory,
  swizzles pointers that cross the trust boundary, and statically identifies
  locations where tainted data must be validated before use.

- **Engineering effort:** Compile-time type errors guide the developer through
  the process of migrating a library into a sandbox. Each compile error points
  to the next required code change---e.g., data that needs to be validated
  before use, or control transfer code that needs to be changed to use the
  RLBox APIs.  This allows developers to incrementally port application code
  one line at a time and test it, in turn.

  By forcing all control and data flow to go though explicit APIs, RLBox
  automatically handles ABI differences in shared data structures and makes it
  easy for developers to switch the underlying isolation mechanisms.
  Importantly, this means that the code interfacing with the library doesn't
  have to change---or be duplicated---across platforms (e.g., on platform where
  NaCl or WebAssembly is not supported developers just need to change one line
  to use the null-sandbox as the underling "isolation mechanism" instead of
  NaCl or Wasm).

We elaborate on both below, and discuss several scenarios, beyond sandboxing,
where our framework can be useful.

## Using tainted types for security

For example, if we consider the example shown earlier, RLBox's compiler errors
would require us to mark the parameters jd, and the jpeg data structure mInfo as
tainted. After this, RLBox would be able to automate insertion of several
checks, such as the pointer bounds checks. RLBox then use compiler errors to
indicate the need for some remaining checks; specifically that the parameters to
memmove must be sanitized before use. We show the same example modified to use
RLBox below.

```cpp
 1: void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
 2:   tainted<jpeg_source_mgr*> src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data.copy_and_verify(...);
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte.copy_and_verify(...),
18:          src->bytes_in_buffer.copy_and_verify(...));
19:   ...
20: }
````

Note that it is still up to the user to figure out how to check the parameters
to memove are safe---i.e. the user has to write safety checks in the three calls
to verify above. In this case, the following checks are required for the decoder.

- The `decoder` being used is a valid object referring to one of the currently
  active image decoders.
- The decoder not being used by a concurrent thread (to prevent race conditions).

To validate the parameters to `memmove`, the following checks must be performed

- The field `next_input_byte` is a pointer within sandbox memory
- The value of `next_input_byte _+ bytes_in_buffer` is also a pointer
  sandbox memory
- The value of `bytes_in_buffer` would not overflow the destination buffer.

<!-- Not leading with the below text for this fix as rlbox only allows
memcpy(tainted dest, tainted src)
OR
memcpy(tainted dest, void* src)

but not
memcpy(void* dest, tainted src)

as I think this may allow bad coding patterns which accidentally smuggles
tainted data

-->
Additionally, to further simplify such code, RLBox also provides overloads of
standard APIs such as memcpy, strcpy etc. that accept tainted values and can be
used to automate such checks.

## Using tainted types to minimize engineering effort

While we have mostly focussed on the security features of RLBox so far, RLBox
has several features designed to greatly reduce engineering effort -- this is
extremely important in practice. Without these features, modifying application
code for correct and safe use sandboxed library can quickly become tedious and
error-prone. We present just two of the main challenges below.

First, SFI toolchains such as NaCl or Wasm have a different ABI than application
code. Specifically, Wasm and NaCl use a 32-bit machine model (LP32) for
performance i.e. the size of "long" and a "void*" in C code is 32-bits. Thus
sharing data-structures between application code and libraries is not
straightforward. Additionally, pointers in these toolchains use a different
format---pointers are stored as relative offsets from the base of the sandbox
heap for performance. Thus any datastructure that is exchanged between the
application and library must account for size differences as well as convert or
"swizzle" the pointer representations appropriately.

Next, libraries are often tightly coupled to application code. For instance,
when sandboxing the use of libjpeg in Firefox, we found that there are 25
different API calls, 5 callbacks and many shared data structures between Firefox
and libjpeg. However, sandboxing mechanisms often require code to use the
sanctioned means of performing function calls and callbacks---the springboards
and trampolines. We cannot reasonably expect application developers to migrate
all interactions with sandboxed library to the trampolines and springboards in a
single step.

RLBox addresses both of these challenges through a combination of automation and
compiler driven feedback. We discuss how RLBox addresses both of these
challenges in more detail below.

### Automatically bridging ABI incompatibilities

RLBox automatically bridges ABI differences by leveraging the type system. In
particular, RLBox uses two types---tainted<T> and tainted_volatile<T> to
automate ABI conversions. The tainted type represents any numeric data
influenced by the sandbox as well as pointers held by the application that refer
to memory inside the sandbox; the tainted_volatile<T> type is used for any data
stored in sandbox memory i.e. it can be directly modified by sandbox code. 
We note that tainted_volatile<T>  is an internal detail of RLBox and is never
exposed to users of RLBox.

This simple division allows RLBox to automatically apply ABI conversions, adjust
field offsets in structs, correct pointer arithmetic, swizzle pointers by
leveraging the type of data being operated on. These types even automatically
bounds check pointers appropriately as they are dereferenced. To demonstrate the
benefits of this automation, we show how one line of code from the previous
example must be changed to account for ABI differences, with and without RLBox.

Consider the following line of code from the previous example of
`fill_input_buffer`.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line _without_ RLBox's automatic ABI conversions and
security checks, the resulting code would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err");
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox lets you write the above exactly as it originally was
written i.e.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

### Incremental migration

RLBox allows us to migrate application code to use the RLBox API one line at a
time. Between each change, the application can be compiled and run as before.
While the details of our approach is explained in detail in our paper
[[**NDG+20**][NDG+20]], the key parts of RLBox that allow for is the concept of
escape hatches---techniques that let us disable RLBox's checks for a piece of
code.

RLBox offers two important escape hatches.

1) The UNSAFE_unverified API may be used on any tainted data to remove the
   tainted wrapper. This allows the application code to disable tainting when
   data must be passed to code that cannot handle tainted data. However, as the
   API name indicates, the use of this API would not enforce the required
   security checks, and is to be used only in the context of migrating code.
   After migration is complete, calls to UNSAFE_unverified APIs must be removed
   or replaced with validator functions that sanitize the given data.

2) The RLBox noop sandbox allows the application code to simply disable the
   underlying isolation mechanism. Instead, this option simply redirects
   function calls back to the application but wraps data as if it were received
   from a sandboxed library. This allows us to test the data validation without
   having to actually use a sandboxed library. Despite its simplicity, the noop
   sandbox plays a very important role! Since, sandboxing mechanisms such as
   WebAssembly have a different ABI, incremental porting cannot be supported as
   automatic ABI conversions are not possible when escape hatches such as
   UNSAFE_unverified were used. Instead during incremental migration, developers
   must use the noop sandbox and switch to Wasm enforcement once this migration
   is complete.

While RLBox's features were designed with the above use cases in mind, we also
discovered several unexpected practical benefits as we incorporated this more
in production code. We discuss these below.

First the incremental porting greatly simplifies the code review process. For
instance, we could commit and get reviews for partial migrations to the RLBox
API, especially since the Firefox browser continued to build and run as before.
Additionally, in the initial migration we simply omitted the validators for use
of UNSAFE_unverified APIs. This allowed to test and deploy the partial migration
on Firefox nightly builds. We then included the data validators in a separate
code review with additional security reviews as part of this change.

Next we discovered that the noop sandbox is critical for downstream projects.
When speaking with developers of the Tor browser, a downstream fork of the
Firefox browser that allows anonymous browsing in the web, we found that Tor was
open to sandbox more libraries than Firefox despite additional performance
overhead due to their higher security requirements. However, the burden of
maintaining a large fork of Firefox with sandboxed libraries was not an
acceptable option. Instead, the RLBox API provides a simple option; Tor
developers could migrate code to use the RLBox API and contribute this upstream
using the noop sandbox---a change that has little to no overhead (< 1%). The
downstream Tor configuration could however specify an isolation mechanism that
provides enforcement.

## Using tainted types outside of sandboxing

Although the focus of RLBox is sandboxing, the techniques used by RLBox tackle
many general problems such as securing interactions between trusted and
untrusted code, disaggregating highly intertwined components, bridging ABI
incompatibilities etc. Thus, before we discuss the future for RLBox sandboxing,
we briefly discuss some additional uses of RLBox's techniques.

TEE runtimes: Applications running on the trusted execution environments such as
Intel SGX must frequently interface with untrusted code; indeed code from the
host OS is also considered untrusted in this context. When reviewing the code of
multiple TEE runtimes, Van Bulck et al.!!!\cite{two-worlds-sgx}!!! discovered
that almost all frameworks have bugs pertaining to use of unchecked data---bugs
that RLBox would prevent by construction. Furthermore, we believe that RLBox may
need little to no modification for use to mitigate such problems in TEE
runtimes.

OS kernels: Operating system kernel code frequently handles userspace pointers,
but must be careful to never dereference them before checking. In fact, prior
work !!!cite{cqual-kernel-ptr}!!! has extended compiler support for C's
attributes to achieve the same affect of having a wrapped type.

Browser IPC layers: Modern browsers employ multiple processes to reduce their
security surface and to employ features such as site-isolation. This
architecture means that data often has to be transferred back and forth between
various processes, some of which are potentially compromised. Like in RLBox, use
of tainted types here would preventing misuse of unchecked data and offer lazy
marshalling of data, improving both security and performance.

Handling untrusted user inputs: More generally, there are large classes of
vulnerabilities that stem from use of unsanitized data. RLBox addresses this
challenge in the context of sandboxing with tainted types and required
validators before data use. Similar solutions employing wrapper types are
possible and have been explored for some of these domains. For example, trusted
types in JavaScript to prevent XSS. Such techniques can also help mitigate SQL
injection, unchecked printf format string vulnerabilities etc.

# Bringing RLBox support to more platforms

We have thus far discussed RLBox in its current form---a framework written used
by C++ programs to sandbox buggy libraries (typically written in C) by
leveraging Wasm as a sandboxing mechanism. However, we believe the concepts
behind RLBox are very general can be easily extended to other languages and
platforms. In this section, we discuss the steps needed to bring RLBox to
additional languages as well as how RLBox allows leveraging platform specific
sandboxing mechanisms such as Intel MPK or CHERI to efficiently enforce
isolation.

## Supporting additional languages

RLBox is currently implemented in C++ and relies on several C++ features to
implement its security checks and automation. However, the underlying principles
can be easily translated to other languages. To better understand how to bring
RLBox to other languages, we first explain how RLBox uses various C++ features.

RLBox primarily relies on the use of tainted types (implemented via C++
templates) and leverages compiler type checking to enforce security properties.
RLBox also permits safe operations on tainted types under certain constraints by
taking advantage of operator overloading, and enforces constraints on these
operations using C++ metaprogramming techniques.

Many other languages include features which can be used to implement the same
general RLBox principles. For instance, statically-typed languages typically
offer some form of generics or templates that can be used to implement
RLBox's tainted and tainted_volatile types. A notable exception here is
C---supporting RLBox in C would require some tool for code generation.
Similarly, many languages allow operator overloading, which RLBox uses to
provide safe operations on tainted types while preserving the original syntax of
the language. (For instance, in C++, RLBox allows dereferencing a tainted<int*>
via the natural '->' and '*' operators, but with automatically inserted bounds
checks.)

Frameworks like RLBox can also be used to enforce security in dynamically
typed languages like JavaScript. However, without compiler assistance, RLBox
cannot provide helpful compile-time assistance, with errors instead manifesting
as runtime errors. While this affects some of the usability of RLBox, we can
still enforce strong security guarantees equivalent to those in C++.

This is just the beginning! We envision a future where RLBox could leverage
many additional language features as well. For instance, RLBox could take
advantage of Rust's affine types to automatically prevent
time-of-check-time-of-use attacks and double fetch attacks. RLBox could also
leverage contracts --- as recently proposed for C++, or for Wasm's interface
types extended with data invariants --- to automatically validate tainted data
prior to use.

<!-- RLBox currently requires extra user specification (in the form of macros)
to fully support structs. However, C++ metaclasses and reflection support will
allow RLBox to support this automatically.-->

## Leveraging advances in hardware isolation

As discussed RLBox's design allows it to easily switch between different
sandboxing mechanisms. We have explored several in [[**NDG+20**][NDG+20]].
However, many more mechanisms exist each offering different
performance/compatibility/security trade-offs. A particular area of interest is
the growth in native hardware based support for sandboxing.

For example, consider Intel's Memory Protection Key features (MPK). This allows
very efficient sandboxing of components, and is largely compatible and easy to
use with existing code as shown in !!! ERIM !!!. Due to RLBox, design, it would
straightforward to implement RLBox support to use MPK as the isolation
mechanism.

Another interesting example is CHERI---an approach to supporting a capability
based model for architectures such as ARM, RISC-V etc. Here, the hardware
enforcement would include and apply bounds checks for all pointers and pointer
dereferences. However, this feature does expand the size of pointers, so it may
not be easy to deploy for all applications especially if the increased pointer
size introduces incompatibilities. Furthermore, it would not be easy to apply
CHERI to just the portion of the code that is compatible; this would make any
data-structures from this portion of code have a different ABI with the rest of
the application. However, since RLBox can automatically adjust for ABI
differences, applications can straightforwardly use CHERI to secure parts of the
application that are compatible with CHERI.

# Making Sandboxing a First Class Part of the Developer Experience

While RLBox has been a boon for our work in Firefox, it's just a starting
point.  Our hope is that library sandboxing will become a first class activity
in future development environments, and that RLBox's capabilities will
ultimately be subsumed by standard parts of tomorrow's languages, toolchains and
package managers. We believe in many cases such support could allow the use of
sandboxed libraries with a level of ease comparable to the use of unsandboxed
libraries today.

Library sandboxing support in language module system or package manager could
allow users to seamlessly choose to sandbox libraries when importing
dependencies.  

Packages could make explicit as part of their specification what
privileges they need to carry out their task, and developers could then choose
if and how to grant these privileges as part of importing a package.

Integrated support for applying tainted types to values produced by sandboxed
libraries could facilitate safe library use, and a natural syntax for invoking
sandboxed functions ala. RLBox could make the transition to using sandboxed
versions of libraries natural and seamless.

Much of the work of writing validators for tainted types could be mitigated by
distributed validators as part of a sandboxed library. While this would entail
placing trust in the author of the validators, because they are a relatively
small amount of code, auditing them could be quite tractable.


!!! TODO --- Clarify (and or remove) the typescript thing.

Language tooling could automatically adjust its build system to appropriately
switch to a sandboxing compiler for libraries which the user wants to sandbox.
The language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing even
more seamless for users, resulting in greater security in the greater software
ecosystem.

All mainstream programming languages support a foreign function interface (FFI)
to invoke function in libraries written in other languages, particularly C, and
many popular languages such as Python, Ruby, and Javascript (ala Node.js) make
extensive use or native code in their standard libraries and package
ecosystems. First class support for sandboxing native code as part of FFI
interfaces, which has been explored in multiple research projects,
!!! TODO --- cite{robusta, sandcrust} probably some more stuff --- node, other langs}.
could not only benefit assurance, but also provide significant
benefits for debugging as native code that violates invariants of the language
runtime lead to notoriously difficult bugs.

Rust is a particularly compelling language ecosystem for an approach like
RLBox. Rust's raison d'être is safety, and it finds use
in many settings where assurance is a paramount, thus the ability to more
safely use native code fits in well with the overall Rust vision.

At the language and tooling level, Rust is well suited to our approach.  Its
support for generics and operator overloading via typeclasses naturally lends
itself to our approach. It's rich macro system and affine types could also
support features not possible in C++ RLBox; such as automatic struct support
and time-of-check-time-of-use prevention.

!!! TODO --- struct support is not explained

The presence of a powerful common build systems and package manager i.e. Cargo,
also lends itself smooth support for library sandboxing.  Extending Cargo with
an additional flag in the Cargo.toml file, to to indicate when a dependency
should be sandboxed could be quite straightforward.

!!! TODO --- some text about syntax being better
<!--
, and automatically augment function return values with
tainted types could be quite natural. 

Of course developers would still responsible for modifying their code to add
validators where needed, however this would encourage developers to consider
sandboxing as an important tool for dependencies.

-->

# Conclusions

!!! TODO --- WIP

- Library sandboxing can be a pratical thing in production systems, currently shipping in firefox
- RLBox shows how to overcome security and software engineering challenges, similar ideas can be applied in other languages and security domains
- First class support for this in other parts of the tool chain i.e. package manager can move us closer to world were sandboxed libraries not significantly harder to use than standard libraries.

# References

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>
