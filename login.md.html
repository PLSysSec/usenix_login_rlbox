<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: Lowering the barrier to in-process sandboxing

# Introduction

Users expect featureful software, and features, it hardly needs
saying, come from code.  The more features, the more code to implement
them.  And the more code, the more bugs---the more _security_ bugs, in
particular.

The latest code rushed out before a marketing deadline, or old code that
hasn't been touched since the developer who wrote it retired, or a
specialized module you licensed: attackers will scour all of them for
bugs to use for exploiting your software and targeting your users.

The problem is especially acute with third-party open source
libraries.  You might care about one thing the library does, but you
ship the whole library, and bugs in any part of it can create to
security problems in your product.  (Unless you fork the library to
remove the extraneous code, but who wants to maintain a fork forever?)
Worse, hackers who find a bug in a popular library can try to deploy
it against every product that embeds the library---including yours.

Computer scientists have been thinking about software insecurity for
fifty years, and they have come up with approaches to mitigate it.
Rewrite your program (or parts of it) in a safer language!  Refuse to
ship new features and keep your program small!  Formally verify the
correctness of your software!  "Privilege separate" your system by
re-architecting it into multiple mutually-distrusting processes!  It's
fair to say that none of these approaches has solved the problem.
Insecure software is all around.

We believe that there is a practical path to improving software
security.  You can take software modules, including third-party
libraries, and _sandbox_ them to constrain what they can do---with low
programmer effort, reasonable runtime overhead, and without wholesale
rewriting or re-architecting---without even creating new OS processes.
The sandboxed module will still have bugs, but those bugs will not (in
most cases; see below) create security vulnerabilities in the
enclosing program.

Consider an image decoding library like libpng.  With sandboxing, we
can restrict this library so it has access to the image it decodes and
the bitmap it produces, _and that's it_.  Or, consider a
spell-checking library like Hunspell.  With sandboxing, we can
restrict this library to just its dictionary and the text it checks.
The application benefits from the library's features, but doesn't
inherit its security flaws.

Over the past two years we have worked with a team at Mozilla to build
a tool, called RLBox, to support sandboxing, and to migrate Firefox to
a model where many third-party libraries run sandboxed.  This new
approach is now shipping in Firefox.  Our experience suggests that
once there is sufficient tooling support that engineers can easily
sandbox libraries, they become increasingly comfortable with and
excited by the opportunities this offers.  For example, while the
initial target of our sandboxing collaboration was a third-party
font-shaping library, Graphite, now Firefox developers and security
engineers are using RLBox to sandbox both third-party libraries and
legacy Mozilla code in domains including media decoding, spell
checking, and even speech synthesis.

We believe that the opportunities extend far beyond Firefox.  After
all, secure messaging apps (e.g., Signal, WhatsApp, and iMessage),
servers and runtimes (e.g., Apache and Node.js), and enterprise tools
(e.g., Zoom, Slack, and VS Code) also rely on third party libraries
for various tasks---from media rendering, to parsing network protocols
like HTTP, image processing (e.g., to blur faces), spell checking, and
automated text completion.  With RLBox, these systems' developers are
empowered to sandbox modules and limit the damage their bugs can
cause.

Recent advances in compilers and processor architectures have made
efficient in-process isolation increasingly practical.  As it turns
out, though, keeping a module from reading or writing memory outside
its data region isn't enough.  Our initial efforts in manually
sandboxing Firefox libraries are a case in point.  Firefox had been
written under the assumptions that the libraries were trustworthy.
Even when isolated, they could return data values that would cause the
(unsandboxed) Firefox code to take unsafe actions, a scenario that
security researchers describe as a "confused deputy" attack.  We tried
to add code to manually check return values for consistency, but
repeatedly found that we had missed cases and left open avenues for
attack.

That's where RLBox comes in.  Using the C++ type system, RLBox
automatically generates the boilerplate code required for sandbox
interaction, and identifies _all_ places where the programmer will
have to add data-checking code.  With RLBox, programmers have a
framework that makes it easy to sandbox libraries (1) _securely_,
ensuring the interface between the untrusted library and the
application code is correct, and with (2) _minimal engineering
effort_, so that the cost of migrating libraries and applications to
sandboxing is not prohibitive.

In the rest of this article we describe the experience that led to
RLBox, how RLBox works and how it leverages the C++ type systems to
make sandboxing practical, and how our type-driven approach can be
used in other domains (e.g., trusted execution environments).  Then we
outline how this approach can translate to languages other than C/C++.
Finally, we end with a vision of what software development could look
like with broader first-class support for sandboxing.

Before closing, we should note that sandboxing is not a panacea.  Some
components must be _correct_, not just isolated, for the system as a
whole to be secure.  The JavaScript just-in-time compilers used by Web
browsers are a notorious example.  With RLBox, you can sandbox
everything else, and focus developer time on getting these few
critical modules right.

# The road to RLBox: library sandboxing in Firefox

Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. These libraries have been a
significant source of vulnerabilities in the browser (e.g., most of the
exploitable bugs found by recent work using symbolic execution were in
third-party libraries [[**BSE20**][BSE20]]).  With collaborators at Mozilla, we
sought to minimize the damage due vulnerabilities in libraries (e.g., (e.g., a
bugs in libvorbis was used to compromise Firefox at Pwn2Own 2018) by
retrofitting Firefox to sandbox these libraries

When we began this project roughly two years ago, we thought the hardest part
would be adapting Google's Native Client (NaCl), a software-based isolation
(SFI) toolkit, to sandbox libraries. (NaCl is designed for sandboxing programs,
not libraries.) This turned out be the easy part. Since then, WebAssembly
toolkits---in particular the Lucet WebAssembly compiler---has made this even
easier (see [[**NGLSS19**][NGLSS19]]).

In fact, the hardest part was the _last mile_, retrofitting Firefox to account
for the now-untrusted libraries.  Firefox was written assuming libraries are
trusted.  To benefit from sandboxing, we had to change its threat model to
assume libraries are untrusted, and modify the browser-library interface
accordingly.  In particular, we had to sanitize all data and regulate control
flow between sandboxed libraries and the browser to prevent malicious libraries
from breaking out of their sandbox. Doing this manually was onerous and error
prone.

**Sandboxing pitfalls**
To illustrate the kinds of security challenges  we encountered, consider, for
instance, refactoring the `fill_input_buffer` JPEG decoder function in Firefox.
This function is called by the libjpeg library whenever it needs more bytes
from Firefox. Additionally, Firefox must save the currently unused input bytes
held by libjpeg to an internal back buffer and resend this to libjpeg along
with additional input.

```cpp
 1: void fill_input_buffer (j_decompress_ptr jd) {
 2:   struct jpeg_source_mgr* src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data;
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte, src->bytes_in_buffer);
18:   ...
19: }
````

When sandboxing libjpeg, we need to refactor this code to account for the
now-untrusted library boundary. Among other things, we must:

- Sanitize `jd`, otherwise the read of `jd->src` on line 2 becomes an
  arbitrary-read gadget.
- Sanitize `src`, otherwise the write to `src->next_input_byte` on line 5
  becomes an arbitrary-write gadget and the `memmove()` on line 16 becomes an
  arbitrary read.
- Sanitize `jd->client_data` to ensure it points to a valid Firefox
  `nsJPEGDecoder` object, otherwise invoking a virtual method on it will hijack
  control flow.
- Sanitize the nested pointer `mInfo.err` on line 10 prior to dereferencing.
- Sanitize the pointer `decoder->mBackBuffer + decoder->mBackBufferLen` used on
  the destination address to `memmove()` on line 16. **TODO: shr, this seems wrong**
- Swizzle pointers like `mInfo.err` and `decoder->mBackBuffer`, i.e., translate
  the pointers to account for the potentially different machine model of the
  sandbox. Both NaCl and WebAssembly have different pointer representations.
- Ensure that multiple threads can't invoke the callback on the same image,
  otherwise we have data race that result in a use-after-free vulnerability.

Missing any of these checks---and these are only a subset of the kinds of
checks we identified in [[**NDG+20**][NDG+20]]---leaves Firefox vulnerable to
confused deputy attacks.  Unfortunately, eliminating these attacks by getting
all the right checks in all the right places for the hundreds of Firefox
functions that interact with libjpeg is hard. Indeed, while migrating Firefox
to this model we repeatedly found that we had overlooked many checks.

**Engineering effort**
But even if we got all the checks right, the upfront engineering effort of
modifying the browser---or even smaller applications---to sandbox each library
this way is huge: We have to retrofit all library calls, adjust data structures
to account for machine model differences between the application and sandbox (a
common issue with SFI toolchains), marshal data to and from the sandbox, etc.
Only then can we run tests to ensure our retrofitting didn't break the
application.  Finally, since Firefox runs on many platforms---including
platforms not yet supported by SFI toolkits like NaCl and Wasm---we have to do
this alongside the existing code that uses the library unsandboxed, using the C
preprocessor to select between the old code and the new code. We tried this
approach. But the patches become so complicated and unwieldy that we couldn't
image anybody maintaining this code, so we built RLBox and started anew.

# The RLBox framework

RLBox is a C++ library designed to make it easier for developers to retrofit
application to securely use sandboxed libraries.  RLBox does this by making
data and control flow at the application-sandbox boundary explicit---at the
type level--and by providing APIs to both mediate these flows and enforce
security checks across the trust boundary.

RLBox mediates data flow using _tainted types_---type wrappers used to
demarcate data originating from the sandbox.  We use tainted values to ensure
that application code cannot use sandboxed data unsafely.  For example, while
application code can add two `tainted<int>`s (to produce another
`tainted<int>`), it cannot branch on such values or use them as indexes into an
array. Instead, the application must validate tainted values before it can use
them.

RLBox mediates control flow by providing APIs for invoking sandboxed functions,
registering host functions as callbacks---to allow the sandbox to call into the
application---and more generally exchange data between the sandbox and
application.  For example, the application must use `sandbox_invoke(sbx_fn,
args...)` to invoke functions in the sandbox; sandboxed functions cannot be
called directly.  Similarly, sandboxed code cannot call into the application
arbitrarily; instead, it can only call functions exposed by the application
using the `sandbox_callback(app_fn)` API. These APIs don't just make the trust
boundary explicitly, they are also key to data flow safety: They impose a
strict tainted-type discipline on all functions by requiring all return values
of sandboxed functions and all callback arguments to be tainted.

As we show next, this tainted-type-driven approach addresses both the security
and engineering challenges we outline above.

## Using tainted types to eliminate confused deputy attacks

RLBox eliminates confused deputy attacks by turning unsafe control- and
data-flows into type errors and, where possible, by performing automatic
security checks.  Concretely, RLBox automatically sanitizes sandbox-supplied
(tainted) pointers to ensure they point sandbox memory, swizzles pointers that
cross the trust boundary, and statically identifies locations where tainted
data must be validated before use.

Consider, for example, the JPEG decoder callback from before. RLBox type errors
would guide us to (1) mark values from the sandbox as tainted (e.g., the `jd`
argument and `src` variable on line 2 below) and (2) _copy and verify_
(otherwise tainted) values we need to use (e.g., `jd->client_data` on line 3
below). 

```cpp
 1: void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
 2:   tainted<jpeg_source_mgr*> src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data.copy_and_verify(...);
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   size_t nr = src->bytes_in_buffer.copy_and_verify(...));
17:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
18:       src->next_input_byte.copy_and_verify(...), nr);
19:   ...
20: }
````

On line 3, 16, and 18 we need to write validators (as C++ lambdas to the
`copy_and_verify` method).  As we describe in [[**NDG+20**][NDG+20]], validators
fall into one of two categories: preserving application invariants (e.g.,
memory safety) or enforcing library invariants.  On line 3, for example, we
ensure that `decoder` points to a valid `nsJPEGDecoder` object not used by a
concurrent thread, while on line 16 we ensure that copying `nr` bytes won't
read past the `mBackBuffer` bounds.

We must get validators right---a bug in a validator is typically a security
bugs. In practice, though, validators are rare and short, typically only a few
lines of code.  (**TODO: shr add stats from.**) Most importantly, by making
these validators explicit, RLBox makes code reviews easier: security engineers
only need to review these validators. 

What's missing in this code snippet is almost as important: we don't write
validators on lines 2, 5, and 10, for example. Instead, RLBox uses runtime
checks to automatically swizzle and sanitize the `src`, `src->next_input_byte`,
and `decoder->mInfo.err` pointers to point to sandbox memory.

## Using tainted types to minimize engineering effort

Compile-time type errors guide the developer through the process of migrating a
library into a sandbox. Each compile error points to the next required code
change---e.g., data that needs to be validated before use, or control transfer
code that needs to be changed to use the RLBox APIs.  This allows developers to
incrementally port application code one line at a time and test it, in turn.

By forcing all control and data flow to go though explicit APIs, RLBox
automatically handles ABI differences in shared data structures and makes it
easy for developers to switch the underlying isolation mechanisms.  This
means that the code interfacing with the library doesn't have to change---or
be duplicated---across platforms (e.g., on platform where NaCl or WebAssembly
is not supported, developers just need to change one line to use the
null-sandbox as the underling "isolation mechanism" instead of NaCl or Wasm).

!!! continue here



While we have mostly focussed on the security features of RLBox so far, RLBox
has several features designed to greatly reduce engineering effort. Indeed
without these features, modifying application code for correct and safe use
sandboxed library can quickly become tedious and error-prone for a couple of
reasons.

First, SFI toolchains such as NaCl or Wasm have a different ABI than application
code. Specifically, Wasm and NaCl use a 32-bit machine model (LP32) for
performance i.e. the size of "long" and a "void*" in C code is 32-bits.
Additionally, pointers in these toolchains use a different format---pointers are
stored as relative offsets from the base of the sandbox heap for performance.
Thus any datastructure that is exchanged between the application and library
must account for size differences as well as convert or "swizzle" the pointer
representations appropriately. RLBox automatically bridges ABI differences by
leveraging the type system.

To demonstrate the benefits of this automation, consider the following line of
code from the previous example of `fill_input_buffer`.

```c++
// mInfo is an object of type jpeg_decompress_struct
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line _without_ RLBox's automation, the resulting code
would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err");
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox allows this with almost no changes but marking `mInfo` as
tainted i.e.

```c++
// mInfo is an object of type tainted<jpeg_decompress_struct>
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

The other major challenge is that libraries are often tightly coupled to
application code; e.g., when sandboxing libjpeg in Firefox, we found
25 function calls to libjpeg and 5 callbacks from libjpeg. However,
sandboxing mechanisms such as Wasm or NaCl require application code to use the
sanctioned means of performing function calls and callbacks---the springboards
and trampolines. We cannot reasonably expect application developers to migrate
all these interactions with sandboxed library to the trampolines and
springboards in a single step.

To overcome this challenge, RLBox allows us to migrate application code to the
RLBox API one line at a time, while RLBox internally invokes the springboards
and trampolines as expected. Between each change, the application can be
compiled and run as before. While the details of our approach are explained
in our paper [[**NDG+20**][NDG+20]], the key idea is that RLBox provides
_escape hatches_ which let us disable RLBox's checks for a piece of code.
In particular, RLBox provides two escape hatches:

1) **The UNSAFE_unverified API** may be used on any tainted data to remove the
   tainted wrapper. This allows the application code to disable tainting when
   data must be passed to code that cannot handle tainted data. Note that this
   API would not enforce the required security checks, and thus is used only in
   the context of migrating code. After migration is complete, calls to
   UNSAFE_unverified APIs must be removed or replaced with validator functions
   that sanitize the given data.

2) **The RLBox noop sandbox** allows the application code to simply disable the
   underlying isolation mechanism. Instead, this option simply redirects
   function calls back to the application but wraps data as if it were received
   from a sandboxed library. This allows developers to test data validation
   separately from the actual isolation mechanism.

Developers use these two features to incrementally migrate application code to
tainted types. Once complete, switching to Wasm-based sandbox enforcement only
requires changing a single line of code. We also discovered some unexpected
practical benefits of this design as we incorporated this more in production
code. We discuss these below.

First, the incremental porting greatly simplifies the code review process. For
instance, we could commit and get reviews for partial migrations to the RLBox
API, since the Firefox browser continued to build and run nightly builds as
before. Additionally, we could explicitly include security reviews when writing
the data validators for tainted data.

Next, we discovered that the noop sandbox is very useful for downstream projects.
When speaking with developers of the Tor browser, a downstream project of the
Firefox browser for anonymous web browsing, we found that Tor was open to
sandboxing more libraries than Firefox given the different security-performance
tradeoffs for anonymous browsing. However, the burden of maintaining a large
fork of Firefox with sandboxed libraries was not an acceptable option. Instead,
we realized that any libraries sandboxed by Tor developers could be contributed
upstream using the noop sandbox (a change that is less 1% overhead), while the
Tor source would include the one line change specifying Wasm enforcement.

## Using tainted types outside of sandboxing

Although the focus of RLBox is sandboxing, the techniques used by RLBox tackle
many general problems such as securing interactions between trusted and
untrusted code, disaggregating highly intertwined components, bridging ABI
incompatibilities etc. Thus, before we discuss the future for RLBox sandboxing,
we briefly discuss some additional uses of RLBox's techniques.

TEE runtimes: Applications running on the trusted execution environments such as
Intel SGX must frequently interface with untrusted code; indeed code from the
host OS is also considered untrusted in this context. When reviewing the code of
multiple TEE runtimes, Van Bulck et al.!!!\cite{two-worlds-sgx}!!! discovered
that almost all frameworks have bugs pertaining to use of unchecked data---bugs
that RLBox would prevent by construction. Furthermore, we believe that RLBox may
need little to no modification for use to mitigate such problems in TEE
runtimes.

OS kernels: Operating system kernel code frequently handles userspace pointers,
but must be careful to never dereference them before checking. In fact, prior
work !!!cite{cqual-kernel-ptr}!!! has extended compiler support for C's
attributes to achieve the same affect of having a wrapped type.

Browser IPC layers: Modern browsers employ multiple processes to reduce their
security surface and to employ features such as site-isolation. This
architecture means that data often has to be transferred back and forth between
various processes, some of which are potentially compromised. Like in RLBox, use
of tainted types here would preventing misuse of unchecked data and offer lazy
marshalling of data, improving both security and performance.

Handling untrusted user inputs: More generally, there are large classes of
vulnerabilities that stem from use of unsanitized data. RLBox addresses this
challenge in the context of sandboxing with tainted types and required
validators before data use. Similar solutions employing wrapper types are
possible and have been explored for some of these domains. For example, trusted
types in JavaScript to prevent XSS. Such techniques can also help mitigate SQL
injection, unchecked printf format string vulnerabilities etc.

# Beyond RLBox

We have thus far discussed RLBox in its current form---a framework that
leverages the C++ type system, template metaprogramming, etc., to sandbox
libraries typically written in C, by leveraging Wasm as a sandboxing mechanism.
In the future, we hope to see RLBox like capabilities supported in other
languages, and also that current and future processor features will further
lower in-process sandboxing overheads.

## Beyond C++

RLBox is currently implemented in C++.  However, the approach
can be directly translated to other languages. To understand how,
we first explain how RLBox uses various C++ features.

RLBox primarily relies on the use of tainted types (implemented via C++
templates) and leverages compiler type checking to enforce security properties.
RLBox also permits safe operations on tainted types under certain constraints by
taking advantage of operator overloading, and enforces constraints on these
operations using C++ metaprogramming techniques.

For instance, statically-typed languages typically offer some form of generics
or templates that can be used to implement RLBox's tainted and tainted_volatile
types. 

A notable exception here is C---supporting RLBox in C would require some tool
for code generation.  Similarly, many languages allow operator overloading,
which RLBox uses to provide safe operations on tainted types while preserving
the original syntax of the language. (For instance, in C++, RLBox allows
dereferencing a tainted<int*> via the natural '->' and '*' operators, but with
automatically inserted bounds checks.)

Frameworks like RLBox can also be used to enforce security in dynamically
typed languages like JavaScript. However, without compiler assistance, RLBox
cannot provide helpful compile-time assistance, with errors instead manifesting
as runtime errors. While this affects some of the usability of RLBox, we can
still enforce strong security guarantees equivalent to those in C++.

This is just the beginning! We envision a future where RLBox could leverage
many additional language features as well. For instance, RLBox could take
advantage of Rust's affine types to automatically prevent
time-of-check-time-of-use attacks and double fetch attacks. RLBox could also
leverage contracts --- as recently proposed for C++, or for Wasm's interface
types extended with data invariants --- to automatically validate tainted data
prior to use.

Rust is a particularly compelling language ecosystem for an approach like
RLBox. Rust's raison d'être is safety, and it finds use
in many settings where assurance is a paramount, thus the ability to more
safely use native code fits in well with the overall Rust vision.

At the language and tooling level, Rust is well suited to our approach.  Its
support for generics and operator overloading via typeclasses naturally lends
itself to our approach. It's rich macro system and affine types could also
support features not possible in C++ RLBox; such as automatic struct support
and time-of-check-time-of-use prevention.


<!-- RLBox currently requires extra user specification (in the form of macros)
to fully support structs. However, C++ metaclasses and reflection support will
allow RLBox to support this automatically.-->

## Leveraging advances in hardware isolation

RLBox's design allows it to be largely independant of the isolation mechanism
it employs. Today it supports software-based-fault isolation through
WebAssembly, as well as traditional process based isolation
[[**NDG+20**][NDG+20]]. Each of these options offers its own trade-offs.
Process isolation is simple, but scales poorly as protection boundary crossing
costs become prohibitive as the number of sandboxes exceed the number of
available cores. WebAssembly offers low overhead protection boundary crossings,
but imposes some additional CPU overhead on sandboxed code, in part due to the
limitations of current toolchains, and in part due to its design.

At present, WebAssembly toolchains offers a practical and portable path to
isolation.  However, it pays a price for platform indepedence in complexity and
performance that is not neccesary for in-process sandboxing. 

Present and future hardware support for in-process isolation can offer
solutions that are simpler and more performant.

The recent ERIM !!! ERIM !!! system, demonstrated how Intel's Memory Protection
Key features (MPK) in conjunction binary inspection can support very low overhead
in-process isolation. XXX blah

XXX This paragraph is not really addressing the main point we want to make,
XXX the point is that CHERI can also support efficient compartmentalization,
XXX the other point about supporting CHERI is interesting but tangential.

Another interesting example is CHERI---an approach to supporting a capability
based model for architectures such as ARM, RISC-V etc. Here, the hardware
enforcement would include and apply bounds checks for all pointers and pointer
dereferences. However, this feature does expand the size of pointers, so it may
not be easy to deploy for all applications especially if the increased pointer
size introduces incompatibilities. Furthermore, it would not be easy to apply
CHERI to just the portion of the code that is compatible; this would make any
data-structures from this portion of code have a different ABI with the rest of
the application. However, since RLBox can automatically adjust for ABI
differences, applications can straightforwardly use CHERI to secure parts of the
application that are compatible with CHERI.


XXX We should add something here about future architecture support for sandboxing.
XXX Note limitations of CHERI (a big hammer for compartmentalization Hovav's IPSEC for
XXX a VPN analogy is nice). Don't understand ERIM deeply enough to have a perspective but
XXX it seems like there should be a pony in the space of better support for efficient
XXX sandboxing--I imagine ERIM is limited in the number of concurrent compartments it can
XXX support because MPK, blah, etc.

# Bringing Sandboxing to the Developer Ecosystem

While RLBox has been a boon for our work in Firefox, it's just a starting
point.  Our hope is that library sandboxing will become a first class activity
in future development environments, and that RLBox's capabilities will
ultimately be subsumed by standard parts of tomorrow's languages, toolchains and
package managers. We believe in many cases such support could allow the use of
sandboxed libraries with a level of ease comparable to the use of unsandboxed
libraries today.

## Package Managers
Library sandboxing support in language module system or package manager could
allow users to seamlessly choose to sandbox libraries when importing
dependencies.  

Packages could make explicit as part of their specification what
privileges they need to carry out their task, and developers could then choose
if and how to grant these privileges as part of importing a package.

Integrated support for applying tainted types to values produced by sandboxed
libraries could facilitate safe library use, and a natural syntax for invoking
sandboxed functions ala. RLBox could make the transition to using sandboxed
versions of libraries natural and seamless.

Much of the work of writing validators for tainted types could be mitigated by
distributed validators as part of a sandboxed library. While this would entail
placing trust in the author of the validators, because they are a relatively
small amount of code, auditing them could be quite tractable.


!!! TODO --- Clarify (and or remove) the typescript thing, or drop it

Language tooling could automatically adjust its build system to appropriately
switch to a sandboxing compiler for libraries which the user wants to sandbox.
The language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing even
more seamless for users, resulting in greater security in the greater software
ecosystem.

In Rust presence of a powerful common build systems and package manager i.e. Cargo,
also lends itself smooth support for library sandboxing.  Extending Cargo with
an additional flag in the Cargo.toml file, to to indicate when a dependency
should be sandboxed could be quite straightforward.


## FFIs and Native Code

All mainstream programming languages support a foreign function interface (FFI)
to invoke function in libraries written in other languages, particularly C, and
many popular languages such as Python, Ruby, and Javascript (ala Node.js) make
extensive use or native code in their standard libraries and package
ecosystems. First class support for sandboxing native code as part of FFI
interfaces, which has been explored in multiple research projects,
!!! TODO --- cite{robusta, sandcrust} probably some more stuff --- node, other langs}.
could not only benefit assurance, but also provide significant
benefits for debugging as native code that violates invariants of the language
runtime lead to notoriously difficult bugs.

# Conclusions

Decades of attempts to detect and mitigate software vulnerabilities have
yielded lackluster results. Even browsers, some of the most heavily targeted
and scrutinized software seem to provide an inexhaustible wellstream of
expoitable vulnerabilities, with the promise of keeping researchers and
attackers employed for at least the next decade.

In-process sandboxing can offer developers and security engineers another
choice---moving legacy, third party, or simply excess code out of their trusted
computing base by sandboxing it---Thus, mitigating the impacts of a compromise.

We have been very satisfied with the results of this approach in Firefox, and
hope that other C++ developers will consider employing RLBox to harden their
applications. 

In the future, we hope that developers of programming languages (and their toolchains
and standard libraries), package managers, and processor architects will consider
supporting in-process sandboxing as a first class activity. Such changes can be 
quite incremental, yet yield substantial benefits for the developer ecosystem.


<!--
- Library sandboxing can be a pratical thing in production systems, currently shipping in firefox
- RLBox shows how to overcome security and software engineering challenges, similar ideas can be applied in other languages and security domains
- First class support for this in other parts of the tool chain i.e. package manager can move us closer to world were sandboxed libraries not significantly harder to use than standard libraries.
-->

# References

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>
