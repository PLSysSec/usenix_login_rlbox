<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: The Road to Less Trusted Code: Lowering the Barrier to In-process Sandboxing

# Introduction

Users expect featureful software, and features, it hardly needs
saying, come from code.  The more features, the more code to implement
them.  And the more code, the more bugs---the more _security_ bugs, in
particular.

The latest code rushed out before a marketing deadline, or old code that
hasn't been touched since the developer who wrote it retired, or a
specialized module you licensed: attackers will scour all of them for
bugs to use for exploiting your software and targeting your users.

The problem is especially acute with third-party open source
libraries.  You might care about one thing the library does, but you
ship the whole library, and bugs in any part of it can create
security problems in your product.  (Unless you fork the library to
remove the extraneous code, but who wants to maintain a fork forever?)
Worse, hackers who find a bug in a popular library can try to deploy
it against every product that embeds the library---including yours.

Computer scientists have been thinking about software insecurity for
fifty years, and they have come up with approaches to mitigate it.
Rewrite your program (or parts of it) in a safer language!  Refuse to
ship new features and keep your program small!  Formally verify the
correctness of your software!  "Privilege separate" your system by
re-architecting it into multiple mutually-distrusting processes!  It's
fair to say that none of these approaches has solved the problem.
Insecure software is all around.

We believe that there is a practical path to improving software
security.  You can take software modules, including third-party
libraries, and _sandbox_ them to constrain what they can do---with low
programmer effort, reasonable runtime overhead, and without wholesale
rewriting or re-architecting---without even creating new OS processes.
The sandboxed module will still have bugs, but those bugs will not (in
most cases; see below) create security vulnerabilities in the
enclosing program.

Consider an image decoding library like libpng.  With sandboxing, we
can restrict this library so it has access to the image it decodes and
the bitmap it produces, _and that's it_.  Or, consider a
spell-checking library like Hunspell.  With sandboxing, we can
restrict this library to just its dictionary and the text it checks.
The application benefits from the library's features, but doesn't
inherit its security flaws.

Over the past two years we have worked with a team at Mozilla to build
a tool, called RLBox, to support sandboxing, and to migrate Firefox to
a model where many third-party libraries run sandboxed.  This new
approach is now shipping in Firefox.  Our experience suggests that
once there is sufficient tooling support that engineers can easily
sandbox libraries, they become increasingly comfortable with and
excited by the opportunities this offers.  For example, while the
initial target of our sandboxing collaboration was a third-party
font-shaping library, Graphite, now Firefox developers and security
engineers are using RLBox to sandbox both third-party libraries and
legacy Mozilla code in domains including media decoding, spell
checking, and even speech synthesis.

We believe that the opportunities extend far beyond Firefox.  After
all, secure messaging apps (e.g., Signal, WhatsApp, and iMessage),
servers and runtimes (e.g., Apache and Node.js), and enterprise tools
(e.g., Zoom, Slack, and VS Code) also rely on third party libraries
for various tasks---from media rendering, to parsing network protocols
like HTTP, image processing (e.g., to blur faces), spell checking, and
automated text completion.  With RLBox, these systems' developers are
empowered to sandbox modules and limit the damage their bugs can
cause.

Recent advances in compilers and processor architectures have made
efficient in-process isolation increasingly practical.  As it turns
out, though, keeping a module from reading or writing memory outside
its data region isn't enough.  Our initial efforts in manually
sandboxing Firefox libraries are a case in point.  Firefox had been
written under the assumptions that the libraries were trustworthy.
Even when isolated, they could return data values that would cause the
(unsandboxed) Firefox code to take unsafe actions, a scenario that
security researchers describe as a "confused deputy" attack.  We tried
to add code to manually check return values for consistency, but
repeatedly found that we had missed cases and left open avenues for
attack.

That's where RLBox comes in.  Using the C++ type system, RLBox
automatically generates the boilerplate code required for sandbox
interaction, and identifies _all_ places where the programmer will
have to add data-checking code.  With RLBox, programmers have a
framework that makes it easy to sandbox libraries (1) _securely_,
ensuring the interface between the untrusted library and the
application code is correct, and with (2) _minimal engineering
effort_, so that the cost of migrating libraries and applications to
sandboxing is not prohibitive.

In the rest of this article we describe the experience that led to
RLBox, how RLBox works and how it leverages the C++ type system to
make sandboxing practical, and how our type-driven approach can be
used in other domains (e.g., trusted execution environments).  Then we
outline how this approach can translate to languages other than C/C++.
Finally, we end with a vision of what software development could look
like with broader first-class support for sandboxing.

Before closing, we should note that sandboxing is not a panacea.  Some
components must be _correct_, not just isolated, for the system as a
whole to be secure.  The JavaScript just-in-time compilers used by Web
browsers are a notorious example.  With RLBox, you can sandbox
everything else, and focus developer time on getting these few
critical modules right.

# The road to RLBox: library sandboxing in Firefox

Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. These libraries have been a
significant source of vulnerabilities in the browser (e.g., most of the
exploitable bugs found by recent work using symbolic execution were in
third-party libraries [[**BSE20**][BSE20]]).  With collaborators at Mozilla, we
sought to minimize the damage due to vulnerabilities in libraries (e.g., a
bug in libvorbis was used to compromise Firefox at Pwn2Own 2018) by
retrofitting Firefox to sandbox these libraries.

When we began this project roughly two years ago, we thought the hardest part
would be adapting Google's Native Client (NaCl), a software-based isolation
(SFI) toolkit, to sandbox libraries. (NaCl is designed for sandboxing programs,
not libraries.) This turned out to be the easy part. Since then, WebAssembly (Wasm)
toolkits---in particular the Lucet Wasm compiler---have made this even
easier (see [[**NGLSS19**][NGLSS19]]).

In fact, the hardest part was the _last mile_, retrofitting Firefox to account
for the now-untrusted libraries.  Firefox was written assuming libraries are
trusted.  To add sandboxing, we had to change its threat model to assume
sandboxed libraries are untrusted, and harden the browser-library interface.
Hardening this interface in-turn required sanitizing data and regulating control flow
between sandboxed libraries and the browser. Thus, ensuring that malicious
libraries could not break out of their sandbox.

**Sandboxing pitfalls**
Hardening the library/application interface manually is labor intensive and
error prone. To illustrate some of the challenges, let's consider updating the
`fill_input_buffer` JPEG decoder function. Libjpeg calls this function whenever
it needs more bytes from Firefox. As seen on line 16, Firefox also saves
the unused input bytes held by libjpeg to an internal back buffer, which it
sends to libjpeg along with the new input bytes.

```cpp
 1: void fill_input_buffer (j_decompress_ptr jd) {
 2:   struct jpeg_source_mgr* src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data;
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte, src->bytes_in_buffer);
18:   ...
19: }
````

When sandboxing libjpeg, we need to make the following changes:

- Sanitize `jd`, otherwise the read of `jd->src` on line 2 becomes an
  arbitrary-read gadget.
- Sanitize `src`, otherwise the write to `src->next_input_byte` on line 5
  becomes an arbitrary-write gadget and the `memmove()` on line 16 becomes an
  arbitrary read.
- Sanitize `jd->client_data` to ensure it points to a valid Firefox
  `nsJPEGDecoder` object, otherwise invoking a virtual method on it will hijack
  control flow.
- Sanitize the nested pointer `mInfo.err` on line 10 prior to dereferencing.
- Sanitize the pointer `decoder->mBackBuffer + decoder->mBackBufferLen` used on
  the destination address to `memmove()` on line 16. **TODO: shr, this seems wrong**
- Swizzle pointers like `mInfo.err` and `decoder->mBackBuffer`, i.e., translate
  the pointers to account for the potentially different machine model of the
  sandbox. Both NaCl and Wasm have different pointer representations.
- Ensure that multiple threads can't invoke the callback on the same image,
  otherwise we have data race that results in a use-after-free vulnerability.

Missing any of these checks---and these are only a limited sample of the kind
of checks required [[**NDG+20**][NDG+20]]---would leave Firefox vulnerable to
confused deputy attacks.  Adding the right checks to the hundreds of Firefox
functions that interact with libjpeg was great deal of tedious work; further,
we repeatedly found many checks that we had overlooked.

**Engineering effort**
The upfront engineering effort of modifying the browser this way was huge.
Beyond adding security checks we had to retrofit all library calls, adjust
data structures to account for machine model differences between the
application and sandbox (a common issue with SFI toolchains), marshal data to
and from the sandbox, etc.  Only then could we run tests to ensure our
retrofitting didn't break the application.  Finally, since Firefox runs on many
platforms---including platforms not yet supported by SFI toolkits like NaCl and
Wasm---we had to do this alongside the existing code that uses the library
unsandboxed, using the C preprocessor to select between the old code and the
new code. The patches to do all this became so complicated and unwieldy that we
couldn't imagine anybody maintaining our code, so we abandoned this manual
approach, built RLBox, and started anew.

# The RLBox framework

RLBox is a C++ library designed to make it easier for developers to retrofit
applications to securely use sandboxed libraries.  RLBox does this by making
data and control flow at the application-sandbox boundary explicit---at the
type level--and by providing APIs to both mediate these flows and enforce
security checks across the trust boundary.

RLBox mediates data flow using _tainted types_---type wrappers used to
demarcate data originating from the sandbox.  It uses tainted values to ensure
that application code cannot use sandboxed data unsafely.  For example, while
application code can add two `tainted<int>`s (to produce another
`tainted<int>`), it cannot branch on such values or use them as indexes into an
array. Instead, the application must validate tainted values before it can use
them.

RLBox mediates control flow by providing APIs for invoking sandboxed functions,
registering host functions as callbacks---to allow the sandbox to call into the
application---and more generally exchanging data between the sandbox and
application.  For example, the application must use `sandbox_invoke(sbx_fn,
args...)` to invoke functions in the sandbox; sandboxed functions cannot be
called directly.  Similarly, sandboxed code cannot call into the application
arbitrarily; instead, it can only call functions exposed by the application
using the `sandbox_callback(app_fn)` API. These APIs don't just make the trust
boundary explicit, they are also key to data flow safety: They impose a
strict tainted-type discipline on all functions by requiring all return values
of sandboxed functions and all callback arguments to be tainted.

As we show next, this tainted-type-driven approach addresses both the security
and engineering challenges we outline above.

## Using tainted types to eliminate confused deputy attacks

RLBox eliminates confused deputy attacks by turning unsafe control- and
data-flows into type errors and, where possible, by performing automatic
security checks.  Concretely, RLBox automatically sanitizes sandbox-supplied
(tainted) pointers to ensure they point to sandbox memory, swizzles pointers that
cross the trust boundary, and statically identifies locations where tainted
data must be validated before use.

Consider, for example, the JPEG decoder callback from before. RLBox type errors
would guide us to (1) mark values from the sandbox as tainted (e.g., the `jd`
argument and `src` variable on line 2 below) and (2) _copy and verify_
(otherwise tainted) values we need to use (e.g., `jd->client_data` on line 3
below). 

```cpp
 1: void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
 2:   tainted<jpeg_source_mgr*> src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data.copy_and_verify(...);
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   size_t nr = src->bytes_in_buffer.copy_and_verify(...));
17:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
18:       src->next_input_byte.copy_and_verify(...), nr);
19:   ...
20: }
````

On line 3, 16, and 18 we need to write validators (as C++ lambdas to the
`copy_and_verify` method).  As we describe in [[**NDG+20**][NDG+20]], validators
fall into one of two categories: preserving application invariants (e.g.,
memory safety) or enforcing library invariants.  On line 3, for example, we
ensure that `decoder` points to a valid `nsJPEGDecoder` object not used by a
concurrent thread, while on line 16 we ensure that copying `nr` bytes won't
read past the `mBackBuffer` bounds.

We must get validators right---a bug in a validator is often a security
bug. In practice, though, validators are rare and short, typically only a few
lines of code.  (**TODO: shr add stats from.**) Most importantly, by making
these validators explicit, RLBox makes code reviews easier: security engineers
only need to review these validators.

What's missing in this code snippet is almost as important: we don't write
validators on lines 2, 5, and 10, for example. Instead, RLBox uses runtime
checks to automatically swizzle and sanitize the `src`, `src->next_input_byte`,
and `decoder->mInfo.err` pointers to point to sandbox memory.

## Using tainted types to minimize engineering effort

In addition to helping developers avoid security pitfalls when using
sandboxed libraries, RLBox also helps minimize the engineering effort
necessary to retrofit applications to use sandboxed libraries.

As one example, RLBox automatically handles the machine-model differences
between sandbox and application code by forcing all control and data flow to
go through explicit APIs and explicit types. For instance, RLBox
automatically swizzles pointers, and accounts for the difference in the size
of "long" and "void*" in sandboxed vs. unsandboxed C code. To demonstrate the
benefits of this automation, consider the following line of code from the
previous example of `fill_input_buffer`.

```c++
// mInfo is an object of type jpeg_decompress_struct
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line _without_ RLBox's automation, the resulting code
would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err");
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox allows this with almost no changes other than marking
`mInfo` as tainted:

```c++
// mInfo is an object of type tainted<jpeg_decompress_struct>
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

Another way RLBox helps minimize engineering effort is by guiding the
developer through the process of migrating a library into a sandbox.
Libraries are often tightly coupled to application code; e.g., when
sandboxing libjpeg in Firefox, we found 25 function calls to libjpeg and 5
callbacks from libjpeg. However, sandboxing mechanisms such as Wasm or NaCl
require application code to use the sanctioned means of performing function
calls and callbacks---the springboards and trampolines. We cannot reasonably
expect application developers to migrate all these interactions with a
sandboxed library to the trampolines and springboards in a single step.

To overcome this challenge, RLBox allows us to migrate application code to
the RLBox API one line at a time, while RLBox internally invokes the
springboards and trampolines as expected. Meanwhile, RLBox's compile-time
type errors guide the developer by pointing to the next required code
change---e.g., data that needs to be validated before use, or control
transfer code that needs to be changed to use the RLBox APIs. Between each
change, the application can be compiled and run as before. While the details
of our approach are explained in our paper [[**NDG+20**][NDG+20]], the key
idea is that RLBox provides _escape hatches_ which let us disable RLBox's
checks for a piece of code. In particular, RLBox provides two escape hatches:

1) **The UNSAFE_unverified API** may be used on any tainted data to remove the
   tainted wrapper. This allows the application code to disable tainting when
   data must be passed to code that does not yet handle tainted data. Note that
   this API would not enforce the required security checks, and thus is used
   only in the context of migrating code. After migration is complete, calls
   to UNSAFE_unverified APIs must be removed or replaced with validator
   functions that sanitize the given data.

2) **The RLBox noop sandbox** allows the application code to simply disable the
   underlying isolation mechanism. Instead, this option redirects
   function calls back to the application, while still wrapping data as if it
   were received from a sandboxed library. This allows developers to test
   data validation separately from the actual isolation mechanism.

Developers use these two features to incrementally migrate application code
to tainted types. Once complete, switching to Wasm-based sandbox enforcement
only requires changing a single line of code. This also means that the code
interfacing with the library doesn't have to change---or be
duplicated---across platforms (e.g., for platforms where NaCl or Wasm
is not supported). We also discovered some unexpected practical benefits of
this design as we incorporated RLBox into production code:

First, the incremental migration greatly simplifies the code review process.
We could commit and get reviews for partial migrations to the RLBox API,
since the Firefox browser continued to build and run nightly builds as
before. Additionally, we could explicitly include security reviews when
writing the data validators for tainted data.

And second, we discovered that the noop sandbox is very useful for downstream
projects. When speaking with developers of the Tor browser, a downstream
project of the Firefox browser for anonymous web browsing, we found that Tor
was open to sandboxing more libraries than Firefox given the different
security-performance tradeoffs for anonymous browsing. However, the burden of
maintaining a large fork of Firefox with sandboxed libraries was not an
acceptable option. Instead, we realized that any libraries sandboxed by Tor
developers could be contributed upstream using the noop sandbox (a change
that is less 1% overhead), while the Tor source would include the one line
change specifying Wasm enforcement.

## Using tainted types outside of sandboxing

Although the focus of RLBox is sandboxing, the techniques used by RLBox
tackle more general problems, such as securing interactions between trusted
and untrusted code, disaggregating highly intertwined components, or bridging
ABI incompatibilities. We briefly discuss some additional potential uses of
RLBox's techniques.

**TEE runtimes:** Applications running on trusted execution environments (TEEs)
such as Intel SGX must frequently interface with untrusted code; even code
from the host OS is considered untrusted in this context. When reviewing the
code of multiple TEE runtimes, Van Bulck et al. [[**BOM+19**][BOM+19]]
discovered that almost all frameworks have bugs pertaining to use of
unchecked data---bugs that RLBox would prevent by construction.

**OS kernels:** Operating system kernel code frequently handles userspace pointers,
but must be careful to never dereference them before checking. RLBox could be used
to automatically insert these checks prior to dereference.  In fact, prior
work [[**JW04**][JW04]] extended the compiler support for C's
attributes to achieve the same effect as having a wrapped type.

**Browser IPC layers:** Modern browsers employ multiple processes to reduce their
security surface and to employ features such as site-isolation. This
architecture means that data often has to be transferred back and forth
between various processes, some of which are potentially compromised. RLBox's
tainted types could prevent the misuse of unchecked data and offer lazy
marshalling of data, improving both security and performance.

**Handling untrusted user input:** More generally, there are large classes of
vulnerabilities that stem from the use of unsanitized data: for instance,
XSS, SQL injection, and printf format-string vulnerabilities. RLBox could be
used to help eliminate these kinds of vulnerabilities: it provides a general
framework for safely handling unsanitized data by using tainted types and
requiring validators before data use. Indeed, similar solutions employing
wrapper types have been explored in some of these domains; for example,
trusted types in JavaScript prevent XSS.

# Beyond RLBox

We have thus far discussed RLBox in its current form---a framework that uses
the C++ type system, template metaprogramming, and  SFI toolkits like
Wasm to securely sandbox libraries typically written in C.  In the
future, we hope to see extensions to other languages, support for sandboxing
libraries written in arbitrary languages, and the adoption of processor
features that can further lower in-process sandboxing overheads.

## Beyond C++

We implemented RLBox in C++ because Firefox is predominately written in C++.
To extend RLBox to other languages, we need to understand how to implement
RLBox's tainted type system.

Our C++ implementation uses templates to implement the generic `tainted<T>`
type, and takes advantage of function and operator overloading to make most of
the tainted type interface transparent.  For example, RLBox overloads pointer
dereferencing---the `->` and `*` operators---to allow dereferencing
`tainted<T*>` values safely, i.e., by automatically sanitizing the underlying
pointer to point to sandbox memory (line 10 in the `fill_input_buffer` example
above).  We also use template metaprogramming to enforce a custom type
discipline.

Many languages have features that are expressive enough to implement our
tainted type system directly or as part of the language toolchain (e.g.,
compiler plugins).

**Statically-typed languages**
RLBox is a natural fit for languages that already enforce type safety
statically.  Statically-typed languages typically offer some form of generics
or templates that can be used to implement tainted types.  Many also allow
function and operator overloading which, like C++, allows us to provide safe
operations on tainted types while preserving the original syntax of the
language.

Rust is a particularly compelling language.  First, Rust's raison d'être is
safety---indeed, the language is used in many settings where assurance is a
paramount---and RLBox can compliment Rust's safety by, for example, making it
easy for Rust programmers to safely integrate C/C++ code into their projects
(which today is considered unsafe).  Second, Rust's macro system and support
for generics and operator overloading (via traits) allows tainted types to be
implemented directly in the language.  Finally, Rust's affine types can even
simplify certain RLBox validators (e.g., validators used to prevent
time-of-check-time-of-use and double fetch attacks).

**Dynamically-typed languages**
In dynamically-typed languages like JavaScript and Python, we can enforce
tainted types dynamically.  This, of course, makes the incremental porting loop
longer since type errors will only manifest at runtime. Luckily, many
industrial dynamically-typed languages have typed extensions to precisely
address this limitations (e.g., TypeScript and Flow extend JavaScript with
types).

**Compiler plugins and toolkits**
For languages not flexible enough to implement the RLBox tainted type system
statically, we envision implementing the type system as part of language
toolchains. For example, for C, we can implement RLBox as Clang plugin (to both
enforce the type system and to generate runtime checks). Alternatively, we can
implement tainted types as part of interface description languages (IDL)
compilers.  As mentioned above, for example, the Mozilla security team is
integrating tainted types into the Firefox IPDL inter-process communication
protocol IDL [[**R20**][R20]].

## Beyond software-based isolation

We designed RLBox to be make it easy for developers plug-in different isolation
mechanism. This makes it easy to migrate code (e.g., by using the noop
sandbox), as we describe above. It also allows developers to use different
isolation mechanisms that have different trade-offs.  For example, while in
production we use WebAssembly for isolation, in [[**NDG+20**][NDG+20]] we
evaluate two other isolation mechanisms: Wasm's predecessor, NaCl, and
traditional process based isolation.  These isolation mechanisms have different
trade-offs.  Process isolation is simple, but scales poorly---protection
boundary crossing costs become prohibitive as the number of sandboxes exceed
the number of available cores.  Wasm and NaCl, on the other hand, scale to
large number of sandboxes and have cheap boundary crossings, but impose an
overhead on the sandboxed code.

At present, Wasm toolchains offers a practical and portable path to isolation.
But this software-based isolation approach will inevitably be slower than
running native code.

Hardware support for in-process isolation can offer solutions that are simple
and more performant. Today, for example, Intel's Memory Protection Key features
(MPK), when used for in-process isolation [[**VED+19**][VED+19]] incurs roughly
1% overhead when used for in-process isolation (but doesn't scale beyond 16
sandboxes).  Looking further out, the CHERI capability-based system will
similarly make in-process isolation---and, memory safety more generally---cheap
on Arm processors [[**R19**][R19]]. By making it easy to use these features
transparently (e.g., for CHERI it can automatically adjust for ABI differences
introduced by capabilities), RLBox could lower the barrier to adopting new
hardware in-process features---and, we hope, this will encourage new hardware
design for in-process isolation.

# Bringing sandboxing to the developer ecosystem

While RLBox has been a boon for our work in Firefox, it's just a starting
point.  Our hope is that library sandboxing will become a first class activity
in future development environments, and that RLBox's capabilities will
ultimately be subsumed by standard parts of tomorrow's languages, toolchains and
package managers. We believe in many cases such support could allow the use of
sandboxed libraries with a level of ease comparable to the use of unsandboxed
libraries today.

## Package managers

In the ecology of package ecosystems there is constant competition between
package authors provide the best package for a given task. Security is among
the ways that package authors can differentiate their package from others. We
have seen this clearly in the Rust ecosystem, where the presence (or absence)
of unsafe code is one way that packages are compared.

Sandboxing is another way that package authors can provided differentiated
value, by integrating sandboxing support into their library.  This could look
like authors distibuting their packages with most or all of the work required
to sandbox that package done upfront by the package author.  Developers could
then choose wether or not enable sandboxing with minimal additional fanfare.

To enable this, the package author could specify an system level sandboxing
policy, (e.g. granting access to the file system or network), and developers
could then choose if and how to grant these privileges when importing a
package.  Much of the work of writing validators for tainted types could also
be mitigated by distributing validators as part of a sandboxed library. While
this would entail placing trust in the author of the validators, because they
are a relatively small amount of code, auditing them could be quite tractable.


<!--
!!! TODO --- Clarify (and or remove) the typescript thing, or drop it
Integrated support for applying tainted types to values produced by sandboxed
libraries could facilitate safe library use, and a natural syntax for invoking
sandboxed functions ala. RLBox could make the transition to using sandboxed
versions of libraries natural and seamless.

M
Language tooling could automatically adjust its build system to appropriately
switch to a sandboxing compiler for libraries which the user wants to sandbox.
The language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing even
more seamless for users, resulting in greater security in the greater software
ecosystem.

In Rust presence of a powerful common build systems and package manager i.e. Cargo,
also lends itself smooth support for library sandboxing.  Extending Cargo with
an additional flag in the Cargo.toml file, to to indicate when a dependency
should be sandboxed could be quite straightforward.
-->

## FFIs and native code

Many popular safe languages such as Python, Ruby, and Javascript (ala Node.js)
make extensive use of unsafe code (most commonly C), in their standard
libraries and package ecosystems through the use of a Foreign Function
Interface (FFI).  

Providing first class support for sandboxing native code is a very natural way
to extend FFI interfaces !!! TODO --- cite{robusta, sandcrust} !!! and
interface generation tools, and bring library sandboxing into a language
toolchain.

Sandboxing unsafe code not only benefits assurance, but can also provide
significant benefits for debugging. Unsafe code that violates invariants of the
language runtime has a long history of generating notoriously difficult bugs.

# Conclusions

Decades of attempts to detect and mitigate software vulnerabilities have
yielded lackluster results. Even browsers, some of the most heavily targeted
and scrutinized software seem to provide an inexhaustible wellstream of
expoitable vulnerabilities, with the promise of keeping researchers and
attackers employed for at least the next decade.

In-process sandboxing can offer developers and security engineers another
choice---moving legacy, third party, or simply excess code out of their trusted
computing base by sandboxing it---Thus, mitigating the impacts of a compromise.

We have been very satisfied with the results of using RLBox in Firefox, and
hope that other C++ developers will consider employing RLBox to harden their
applications.

In the future, we hope that developers of programming languages (and their toolchains
and standard libraries), package managers, and processor architects will consider
supporting in-process sandboxing as a first class activity. Such changes can be 
quite incremental, yet yield substantial benefits for the developers and security
engineers.

<!--
- Library sandboxing can be a pratical thing in production systems, currently shipping in firefox
- RLBox shows how to overcome security and software engineering challenges, similar ideas can be applied in other languages and security domains
- First class support for this in other parts of the tool chain i.e. package manager can move us closer to world were sandboxed libraries not significantly harder to use than standard libraries.
-->

# References

**TODO: sort these**

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285

[**BOM+19**] J. Van Bulck, D. Oswald, E. Marin, A. Aldoseri, F. D. Garcia, and F. Piessens. "[A Tale of Two Worlds: Assessing the Vulnerability of Enclave Shielding Runtimes][BOM+19]". In _2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19)_. ACM, Nov. 2019.
[BOM+19]: https://people.cs.kuleuven.be/~jo.vanbulck/ccs19-tale.pdf

[**JW04**] R. Johnson and D. Wagner. "[Finding User/Kernel Pointer Bugs With Type Inference][JW04]". In _Proceedings of USENIX Security 2004_. USENIX, Aug. 2004.
[JW04]: https://www.usenix.org/event/sec04/tech/full_papers/johnson/johnson_html/

[**R19**] Richard Grisenthwaite. "[A Safer Digital Future, By Design][R19]". arm Blueprint. Oct. 2019.
[R19]: https://www.arm.com/blogs/blueprint/digital-security-by-design

[**R20**] Tom Ritter. "[Support tainting data received from IPC][R20]". Mozilla Bug 1610005. Jan. 2020.
[R20]: https://bugzilla.mozilla.org/show_bug.cgi?id=1610005

[**VED+19**] A. Vahldiek-Oberwagner, E. Elnikety, N.O. Duarte, M. Sammler, P. Druschel, and D. Garg "[ERIM: Secure, Efficient In-process Isolation with Protection Keys (MPK)][VED+19]".  In _Proceedings of USENIX Security 2019_. USENIX, Aug. 2004.
[VED+19]: https://www.usenix.org/conference/usenixsecurity19/presentation/vahldiek-oberwagner

# Authors

**Bios and pics go here**

_Shravan Narayan_

Bio, pic:

_Tal Garfinkel_

Bio, pic:

_Craig Disselkoen_

Bio, pic:

_Hovav Schacham_

Bio, pic:

_Deian Stefan_

Bio, pic:

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>
