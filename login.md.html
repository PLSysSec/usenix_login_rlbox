<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: Lowering the barrier to in-process sandboxing

# Introduction

Modern software makes heavy use of third-party libraries. While this is
critical for developer productivity, it is also a security nightmare. Third
party libraries, today, are completely trusted. Unfortunately, this means that
bugs in any library can be easily exploited to compromise the entire
application. Further, attacks on software supply chains are becoming more
prevalent: attackers are compromising (and sometimes buying) the accounts of
software maintainers to slip backdoored code into popular libraries.

There is a practical alternative to today's trust-everything model: we can
enforce least privilege by sandboxing libraries. Thus, minimizing the damage
inflicted by buggy or malicous libraries.  While this may sound radical at
first glance, in our experience it is often not a significant departure from
how we use libraries today.

As a result of basic principles of modularity and good interface design, most
libraries do not require unfettered access to the processes entire address
space. The also require only a limited set of OS privileges to accomplish their
task. This makelibrary especially well suited to running in a de-privileged and
memory isolated context.

For example, image decoders like libjpeg and libpng don't need access to
anything but the image buffers they operate on, OpenSSL doesn't need access to
anything but the socket it's reading from and the bytestream it's writing the
decrypted HTTP stream to, and spell checkers like Hunspell don't need access to
anything but dictionary files and the string it's spell checking.

These are just a few examples, however, we believe other examples abound.
Unfortunately, library sandboxing has suffered from a chicken and egg problem.
Without practical tools for securely sandboxing libraries with minimal
performance overhead and engineering effort, developers and security engineers
are not looking for these opportunities.

We believe it is time for a shift in this perspective.  Over the past two years
we have worked with a team at Mozilla to migrate Firefox to a model where a
variety of different third party libraries run sandboxed. This new approach has
been shipping in Firefox since XXX. Our experience suggests that once their is
sufficient tooling support that engineers can easily sandbox libraries, they
become increasingly comfortable with and excited by the opportunities this
offers.

For example, while we began with third party font shaping libraries, now
Firefox developers and security engineers are using RLBox for media decoding,
spell checking, even speech synthesis. Similar opportunities exist in many
other application domains. For example, secure messaging apps (e.g., Signal,
WhatsApp, and iMessage), servers and runtimes (e.g., Apache and Node.js), and
enterprise tools (e.g., Zoom, Slack, and VS Code) also rely on third party
libraries for various tasks---from media rendering, to parsing network
protocols like HTTP, image processing (e.g., to blur faces), spell checking,
and automated text completion. 

Recent advances in compiler and processor architecture space have made
efficient in-process isolation increasingly practical in a wide range of use
cases.  But, to make library sandboxing a goto tool in more software
engineering environments, the missing element has been a common framework that
makes it easy to sandbox libraries (1) _securely_, to correctly enforce a
secure interface between the untrusted library and the application, and (2)
_effectively_, to minimize the engineering effort required to sandbox a
library.

Our own experience sandboxing libraries in Firefox reflects this. Our initial
attempts to manually sandbox third party libraries were labor intensive, and
very prone to security bugs. In contrast, once we developed the RLBox framework
[[**NDG+20**][NDG+20]] the incremental work to sandbox new libraries became
minimal, and more opportunities to sandbox additional parts of the application
became apparent.

In the rest of this article we describe how RLBox works, how it leverages the
C++ type systems to make sandboxing practical, and how this type-driven
approach can be used in other domains (e.g., trusted execution environments).
Then we outline what we need to do to bring sandboxing to other languages.
Finally, we end with a vision of what software development could look like with
broader first-class support for sandboxing.

# Library sandboxing in Firefox with RLBox


Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. Since these libraries have been
a significant source of vulnerabilities in the browser (e.g., most of the
browser bugs found by Sys this year were in third-party libraries
[[**BSE20**][BSE20]]), by retrofitting Firefox to sandbox libraries we can
minimize the damage due to library bugs (e.g., like the libvorbis bug at
Pwn2Own 2018 to compromise Firefox).

We started this project roughly two years thinking the hardest part of
sandboxing libraries is adopting a software-based isolation (SFI)
toolkit---Google's NativeClient (NaCl) at the time---for library sandboxing .
(NaCl is designed for sandboxing programs, not libraries.) This turned out be
the easy part and, since then, WebAssembly toolkits---in particular, the Lucet
WebAssembly compiler---has made this even easier (see
[[**NGLSS19**][NGLSS19]]).

The hard part was retrofitting Firefox to account for now-untrusted libraries.
Firefox was written assuming libraries are trusted.  To benefit from
sandboxing, we had to change our threat model to assume libraries are
untrusted, and modify the browser-library interface accordingly.  In
particular, we had to sanitize all data and regulate control flow between
sandboxed libraries and the browser to prevent libraries from breaking out of
their sandbox.

For instance consider a single function in Firefox's JPEG decoder called
`fill_input_buffer`. This is Firefox code for the fill_input buffer callback: a
function invoked by libjpeg when requesting more bytes from the input stream.
Below the Firefox code tries to expand the input data buffer. If it is unable to
do so, it writes and error code to the `mInfo` structure--- a datastructure
controlled by JPEG.

```c++
void fill_input_buffer (j_decompress_ptr jd) {
  ...
  JOCTET * buf = (JOCTET *) realloc(...);
  if (!buf) {
    decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
    ...
  }
}
```

This code snippet has multiple points of failure in the form of easy to miss
security checks.

- Failing to bounds check `err` prior to dereferencing it can result in a write
  gadget.
- Failing to swizzle the nested pointer mInfo.err prior to dereferencing, can
  result in a write gadget or crash.
- Failing to prevent multiple threads from invoking the above callback on the
  same image can induce a data race and use-after-free vulnerability in turn.

<!-- Actually I am thinking the above simple example may be enough -->
<!-- Including one more, but we can remove this if needed -->

Consider another example the same `fill_input_buffer` function.

```c++
void fill_input_buffer (j_decompress_ptr jd) {
  struct jpeg_source_mgr * src = jd->src;
  ...
  memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
    src->next_input_byte, src->bytes_in_buffer);
}
```

Since this callback is invoked by libjpeg, the callback parameters must be
sanitized prior to use. Failure to do so allows control of some of the arguments
of the memmove function giving libjpeg a write gadget.

These are simply two examples from a single function in the JPEG decoder. When
the effort to add required security checks to the hundreds of functions that
interact with libjpeg, it is extremely easy to make mistakes. Indeed, while
migrating Firefox to this model we made numerous mistakes---overlooking attack
vectors and discovering many bugs only after building RLBox to help detect them.
Moreover, the upfront engineering effort of retrofitting the browser to sandbox
any library was huge: We had port calls to library, adjust data structures to
account for ABI differences (NaCl's machine model is different from the
application), copy values to and from the sandbox, etc.  _in one step_. Only
then could we run tests to ensure our retrofitting didn't break the browser.
Since Firefox runs on many platforms---including platforms not supported by our
SFI toolkit---we had to do this alongside the existing code that used the
library unsandboxed, using a guard `#if SANDBOXED` to select between the old
code and the new code. The patches become so complicated and unwieldy, we
scrapped the effort and built RLBox to address these challenges.

-----


First, {\it engineering effort}---we need to minimize the upfront work required
to change the renderer to use sandboxing, especially as this is multiplied
across dozens of libraries;
%
minimizing changes to libraries is also important as this can
significantly increase the burden of tracking upstream changes.
%
Second, {\it security}---the renderer was not built
to protect itself from libraries; thus, we have to sanitize all data and regulate control
flow between the library and renderer to prevent libraries from breaking out of
the sandbox.
%
In our experience, bugs at the library-renderer boundary are not only easy to
overlook, but can nullify any sandboxing effort---and other developers,
not just us, must be able to securely sandbox new libraries.
%
Finally, {\it efficiency}---the renderer is performance critical, so adding
user-visible latency is not acceptable.

To help us address these challenges, we develop a framework called \sys that
makes data- and control-flow at the library-renderer interface explicit, using
types. Unlike prior approaches to sandbox automation that rely on extensive
custom analysis frameworks~(\S\ref{sec:related}), \sys is simply a
library\footnote{
Our only external tooling is a \textasciitilde{}100LOC Clang
plugin, described in Section~\ref{subsec:impl_taint}, that makes up for C++'s
currently limited  support for reflection on structs.
}
that leverages the C++ type system and is easy to incorporate into \ff's
predominantly C++ codebase.

Using type information, \sys can identify where security checks are needed,
automatically insert dynamic checks when possible, and force compiler errors
for any security checks that require additional user intervention.  Our
type-driven approach enables a systematic way to migrate \ff's renderer to use
sandboxed libraries and allows \sys to support secure and
efficient sharing of data structures between the renderer and library (e.g., by
making shared memory operations safe and by lazily copying data out of the sandbox).




# Why do we need a common sandboxing Framwork

XXX elaborate on security justifications and migration justifications

RLBox is a C++ framework that helps developers migrate and maintain code in
application to safely use sandboxed libraries.


The applications-library boundary is tightly coupled and by default application
code is written assuming libraries are trusted. To benefit from sandboxing
requires changing our threat model to assume libraries are untrusted, and modify
the renderer-library interface accordingly (e.g, to sanitize untrusted inputs).

While migrating to this model we made numerous mistakes—overlooking attack
vectors and discovering many bugs only after building RLBox to help detect them.
We present a few illustrative examples below.

!!!!TODO!!!!

We built the RLBox framework to tackle these challenges. RLBox is a pure C++
library that helps developers migrate and maintain code in application to safely
use sandboxed libraries. RLBox does this by providing APIs to invoke sandboxed
functions, permit callbacks into the host application and more generally
exchange data between the sandbox and application. These APIs are built around
tainted types---these are wrapper types used to mark data received from the
sandboxed library and impose a simple static information flow control (IFC)
discipline.

Thus, to migrate application code from use of an unsandboxed library, to a
sandboxed library we must simply use the RLBox API for all interactions with the
sandboxed library.

This simple design for RLBox allows us to provide several features including

- Ensuring the resulting code has security checks in appropriate locations
- Providing a systematic approach to migrating application code to the RLBox API
  accounting for ABI differences, data marshalling etc. automatically
- Easily enabling or disabling different isolation technologies.

## Eliminating confused deputy attacks

RLBox eliminated confused deputy attacks by mediating data and control flows at
the renderer-sandbox interface and enforce security checks across this trust
boundary. RLBox can do this by leveraging its type system and API design.

RLBox mediates data flow with tainted types that impose a simple static
information flow control (IFC) discipline. This ensures that sandbox data is
validated before any potentially unsafe use. It also prevents pointer leaks into
the sandbox that could break ASLR.

RLBox mediates control flow through a combination of tainted types and API
design. Tainting, for example, allows RLBox to prevent branching on tainted
values that have not been validated. API design, on the other hand, is used to
restrict control transfers between the renderer and sandbox. For instance, the
renderer must use sandbox_invoke() to invoke functions in the sandbox; any
callback into the renderer by the sandbox must first be registered by the
renderer using the sandbox_callback(callback_fn) API.

As a result, RLBox enforces security through two approaches. First, it automates
security checks such as bounds checking sandbox-supplied pointers to ensure they
point within sandbox memory as well as the identifying of locations where
tainted data must be validated. Second, RLBox uses compile-time type errors to
guide the developer through the process of migrating a library into a sandbox.
Each compile error points to the next required code change---e.g., data that
needs to be validated before use, or control transfer code that needs to be
changed to use RLBox APIs.

For example, if we consider the two examples shown earlier, RLBox's compiler
errors would require us to mark the parameters jd, and the jpeg data structure
mInfo as tainted. After this, RLBox would be able to automate all checks in the
first example, leaving the code as is. For the second example, above RLBox would
use compiler errors to indicate that parameters to memmove must be sanitized
before use as shown below.

```c++
void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
  tainted<jpeg_source_mgr*> src = jd->src;
  ...
  memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
    src->next_input_byte.verify(...), src->bytes_in_buffer.verify(...));
}
```

Note that it is still up to the user to figure out how to check the parameters
to memove are safe---i.e. the user has to write safety checks in the two
locations with "..." above. In this case, the following checks are required

- The field `next_input_byte` is a pointer within sandbox memory
- The value of `next_input_byte _+ bytes_in_buffer` is also a pointer within
  sandbox memory
- The value of `bytes_in_buffer` is would not overflow `mBackBufferLen`.

In practice, to simplify such code, RLBox also provides some overloads of
standard APIs such as memcpy, strcpy and more that accept tainted values and
automated these checks.

## Minimizing sandboxing engineering effort

While we have focussed on the security features of RLBox so far, RLBox has
several features designed to greatly reduce engineering effort -- in practice,
this is extremely important as without these features, migrating application
code can quickly become tedious and error-prone. Below we present some of the
challenges that prompted us S

For instance, SFI toolchains such as NaCl or Wasm have a different ABI than
application code. Wasm and NaCl use a 32-bit machine model (LP32) i.e. the size
of "long" and a "void*" in C code is 32-bits. Thus sharing data-structures
between application code and libraries is not straightforward. Additionally it
is not just differences in sizes, pointers in these toolchains have an
altogether different format---pointers are stores as relative offsets from the
base of the sandbox heap for performance. Thus any datastructure that are
exchanged between the application and library must account for size differences
as well as convert or "swizzle" the pointer representations appropriately.

The other challenge in using the sandboxed libraries is performing the code
changes required to migrate to using sandboxed libraries. Application may be
very tightly coupled with the library that is to be sandboxed. For instance,
when sandboxing the use of libjpeg in Firefox, we found that there are 25
different API calls, 5 callbacks and many shared data structures between Firefox
and libjpeg. We cannot reasonably expect application developers to migrate all
interactions with sandboxed library to the RLBox API in a single step.

RLBox addresses both of these challenges through a combination of automation and
compiler driven feedback. We discuss how RLBox addresses both of these
challenges in more detail below.

### Automatically bridging ABI incompatibilities

RLBox automatically bridges ABI differences by leveraging the type system. In
particular, RLBox uses two types---tainted<T> and tainted_volatile<T> to
automate ABI conversions. The tainted type represents any numeric data
influenced by the sandbox as well as pointers held by the application that refer
to memory inside the sandbox, while the tainted_volatile<T> type is used for any
data stored in sandbox memory i.e. can be modified by sandbox code.

This simple division allows RLBox to automatically apply ABI conversions, adjust
field offsets in structs, correct pointer arithmetic, swizzle pointers as
needed, and even automatically bounds check pointers appropriately as they are
dereferenced. The easiest way to demonstrate the importance of this automation.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line with RLBox's automatic ABI conversions and security
checks, the resulting code would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err" /* field */);
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox lets you write the above exactly as it originally was
written i.e.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

We note that tainted_volatile<T>  is an internal detail of RLBox
and is never exposed to users of RLBox.

### Incremental migration

RLBox allows us to migrate application code to use the RLBox API one line at a
time. Between each change, the application can be compiled and run as before.
While the precise approach is explained in detail in our paper, the key parts of
RLBox that allow for is the concept of escape hatches---techniques that let us
disable RLBox's checks for a piece of code.

RLBox offers two important escape hatches.

1) The UNSAFE_unverified API may be used on any tainted data to remove the
  tainted wrapper. This allows the application code to disable tainting of data
  when data must be passed to code that cannot handle tainted data. However, as
  the API name indicates, the use of this API would not enforce the required
  security checks, and is to be used only in the context of migrating code.
  After migration is complete, calls to UNSAFE_unverified APIs must be removed
  or replaced with validator functions that sanitize the given data.

2) The RLBox API allows the application code to choose the underlying isolation
  mechanism including a noop sandbox option. This option simply redirects
  function calls back to the application but wraps data as if it were received
  from a sandboxed library. This allows us to test the data validation without
  having to actually use a sandboxed library. But the noop sandbox plays an even
  more important role! Since, sandboxing mechanisms such as WebAssembly have a
  different ABI, incremental porting cannot be supported as there is no way to
  apply ABI conversions when escape hatches such as UNSAFE_unverified were used.
  Instead the incremental migration approach would be to use the noop sandbox
  during incremental migration and switch to Wasm enforcement once this
  migration is complete.


While these features were designed with the above use cases in mind, we also
discovered several unexpected practical benefits from the above feature set,
including their interactions after the publication as we incorporated this more
in production code. We discuss these below

First the incremental porting greatly simplifies the code review process. For
instance, we could commit and get reviews for partial migrations to the RLBox
API as this do not the Firefox browser continued to build and run as before.
Additionally, in the initial migration we simply omitted the validators for use
of UNSAFE_unverified APIs. This allowed to test and deploy the partial migration
on Firefox nightly builds. We then included the data validators in a separate
code review with additional security reviews as part of this change.

Next we discovered that the noop sandbox is critical for downstream projects.
When speaking with developers of the Tor browser, a downstream fork of the
Firefox browser that allows anonymous browsing in the web, we found that Tor was
open to sandbox more libraries than Firefox despite additional performance
overhead due to their higher security requirements. However, the burden of
maintaining a large fork of Firefox with sandboxed libraries was not an
acceptable option. Instead, the RLBox API provides a simple option; Tor
developers could migrate code to use the RLBox API but contribute upstream using
the noop sandbox. They could then switch the configuration in the Tor browser to
use an isolation mechanism that provides enforcement. Since using the noop
sandbox little to no overhead (< 1%), this is a reasonable option.

Indeed this flexibility in switching between memory isolation also allows easy
experimentation with many new hardware features. We discuss this next.

## Leveraging advances in SFI and hardware isolation

As discussed RLBox's design allows it to be agnostic to the memory isolation
technique. For example, consider Intel's Memory Protection Key features (MPK)
which allow very efficient sandboxing of components. It would straightforward to
implement RLBox support to use MPK as the isolation mechanism.

RLBox, also allows leveraging more complicated hardware security mechanisms. For
instance consider ARM Cheri, which is a hardware feature that converts pointers
into capabilities that apply bounds checks. Since this feature expands the size
of pointers it may not be easy to deploy for all applications especially if the
increased pointer size introduces incompatibilities. Furthermore it would not be
easy to apply this to just a portion of the code as any data-structures from
this portion of code would have ABI incompatibilities with the rest of the
application. However, since the RLBox can automatically adjust for ABI
differences, applications can straightforwardly use Cheri to secure a single
component in an application.

# Language support for Sandboxing with Tainted Types

Though we implemented RLBox in C++ to sandbox C libraries, we believe the
underlying principles translate to other languages. Going even further, we
propose first class support for RLBox in languages and their tooling. Not only
would this make the use of tainted type more seamless, it would allow developers
to sandbox dependencies as they first import them into their project.

## RLBox's use of language features

To understand how to bring RLBox to other languages, we need to first
understand which C++ features RLBox relies on. Primarily, RLBox uses tainted
types (implemented via C++ generics) and leverages compiler type checking to
enforce security properties. RLBox also permits safe operations on tainted
types under certain constraints by taking advantage of operator overloading,
and enforces constraints on these operations using C++ metaprogramming
techniques.

Many other languages include features which can be used to implement the same
general RLBox principles. For instance, many statically-typed languages offer
some form of generics or templates which could be used to implement RLBox's
tainted and tainted_volatile types. A notable exception here is
C---supporting RLBox in C would require some tool for code generation.
Similarly, many languages allow operator overloading, which RLBox uses to
provide safe operations on tainted types while preserving the original
syntax of the language. (For instance, in C++, RLBox allows dereferencing
a tainted<int*> via the natural '->' and '*' operators, but with automatically
inserted bounds checks.)

Frameworks like RLBox can also be used to enforce security in dynamically
typed languages like JavaScript. However, without compiler assistance, RLBox
cannot provide helpful compile-time assistance, which is especially important
during incremental porting. Instead, the errors would manifest as runtime
errors. Thus, while the usability of RLBox would be reduced, the security
guarantees would be the same.

This is just the beginning! We envision a future where RLBox could leverage
many additional language features as well. For instance, RLBox could take
advantage of Rust's affine types to automatically prevent
time-of-check-time-of-use attacks and double fetch attacks. RLBox could also
leverage contracts --- as recently proposed for C++, or for Wasm's interface
types --- to automatically validate tainted data prior to use.

<!-- RLBox currently requires extra user specification (in the form of macros)
to fully support structs. However, C++ metaclasses and reflection support will
allow RLBox to support this automatically.-->

# Making Sandboxing a First Class Part of the Developer Experience

In the further future, we envision first-class support in languages and their
tooling for RLBox, and for sandboxing more broadly. First-class support in a
language module system or in a package manager could allow users to
seamlessly choose to sandbox libraries when importing dependencies, and could
also automatically apply tainted types to all of the values coming out of the
library. First-class support could also ensure that the syntax for using
RLBox is as natural as possible -- for instance, invoking sandbox functions
could share the same syntax as ordinary function calls. Language tooling
could automatically adjust its build system to appropriately switch to a
sandboxing compiler for libraries which the user wants to sandbox. The
language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing
even more seamless for users, resulting in greater security in the greater
software ecosystem.

Most languages support FFI to libraries written in other languages, particularly
C. Integrating RLBox into the natural FFI support for a language would help
automatically ensure that C-language libraries do not violate the invariants
expected by higher-level constructs in the source language. It would also
provide greater security in general, as memory safety bugs in the C-language
library would be prevented from compromising the larger application; an effort
explored by multiple academic papers.
!!!tocite{robusta, sandcrust, some node thing?, lookup language sandboxes}!!!!.

Rust in particular offers an exciting target for RLBox. Rust satisfies the
minimum requirements for RLBox's types in that it offers generics and allow
specifying operator behavior via typeclasses. Additionally, Rust's rich macro
system and affine types allows it to provide even more features than the C++
library; namely automatic struct support and time-of-check-time-of-use
prevention. Most importantly Rust has an easy to use and powerful build and
package management configured via a Cargo.toml file. Providing an extra flag
here to indicate when a dependency should be sandboxed would be straightforward.
The Rust build system could then compile this dependency to WebAssembly
(something that is already supported), and automatically wrap the data returned
by functions in these dependencies with tainted types. By doing this, Rust can
offer a single configuration that allows users to sandbox dependencies. Of
course developers are still responsible for modifying their code to add
validators where needed, however this would encourage developers to consider
sandboxing as an important tool for dependencies.

# Conclusions

!!! TODO

# References

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285



<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>

