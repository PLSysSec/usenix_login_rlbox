<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: Lowering the barrier to in-process sandboxing

# Introduction

Modern software makes heavy use of third-party libraries. While this is
critical for developer productivity, it is also a security nightmare. Third
party libraries, today, are completely trusted. Unfortunately, this means that
bugs in any library can be easily exploited to compromise the entire
application. Further, attacks on software supply chains are becoming more
prevalent: attackers are compromising (and sometimes buying) the accounts of
software maintainers to slip backdoored code into popular libraries.

There is a practical alternative to today's trust-everything model: we can
enforce least privilege by sandboxing libraries. Thus, minimizing the damage
inflicted by buggy or malicious libraries.  While this may sound radical at
first glance, in our experience it is often not a significant departure from
how we use libraries today.

As a result of basic principles of modularity and good interface design, most
libraries do not require unfettered access to the processes entire address
space. They also require only a limited set of OS privileges to accomplish their
task. Together these properties make libraries especially well suited to
running in de-privileged and memory isolated contexts.

For example, image decoders like libjpeg and libpng don't need access to
anything but the image buffers they operate on, OpenSSL doesn't need access to
anything but the socket it's reading from and the bytestream it's writing the
decrypted HTTP stream to, and spell checkers like Hunspell don't need access to
anything but dictionary files and the string it's spell checking.

These are just a few examples, however, we believe other examples abound.
Unfortunately, library sandboxing has suffered from a chicken and egg problem.
Without practical tools for securely sandboxing libraries with minimal
performance overhead and engineering effort, developers and security engineers
are not looking for these opportunities.

We believe it is time for a shift in this perspective.  Over the past two years
we have worked with a team at Mozilla to migrate Firefox to a model where a
variety of different third party libraries run sandboxed. This new approach has
been shipping in Firefox since XXX. Our experience suggests that once their is
sufficient tooling support that engineers can easily sandbox libraries, they
become increasingly comfortable with and excited by the opportunities this
offers.

For example, while we began with third party font shaping libraries, now
Firefox developers and security engineers are using RLBox for media decoding,
spell checking, even speech synthesis. Similar opportunities exist in many
other application domains. For example, secure messaging apps (e.g., Signal,
WhatsApp, and iMessage), servers and runtimes (e.g., Apache and Node.js), and
enterprise tools (e.g., Zoom, Slack, and VS Code) also rely on third party
libraries for various tasks---from media rendering, to parsing network
protocols like HTTP, image processing (e.g., to blur faces), spell checking,
and automated text completion. 

Recent advances in compiler and processor architecture space have made
efficient in-process isolation increasingly practical in a wide range of use
cases.  But, to make library sandboxing a goto tool in more software
engineering environments, the missing element has been a common framework that
makes it easy to sandbox libraries (1) _securely_, to correctly enforce a
secure interface between the untrusted library and the application, (2)
_effectively_, to minimize the engineering effort required to sandbox a
library, and (3) _modularly_, to support different isolation techniques---from
NaCl, to WebAssembly, and hardware isolation mechanisms like Intel's Memory
Protection Key (MPK).

Our own experience sandboxing libraries in Firefox reflects this. Our initial
attempts to manually sandbox third party libraries were labor intensive, and
very prone to security bugs. In contrast, once we developed the RLBox framework
[[**NDG+20**][NDG+20]] the incremental work to sandbox new libraries became
minimal, and more opportunities to sandbox additional parts of the application
became apparent. We think other applications can benefit from RLBox and as an
example, in [[**NDG+20**][NDG+20]], we demonstrated its use sandboxing
third-party Apache and native Node.js modules.

In the rest of this article we describe the experience that led to RLBox, then
we describe how RLBox works, how it leverages the C++ type systems to make
sandboxing practical, and how our type-driven approach can be used in other
domains (e.g., trusted execution environments).  Then we outline what we need
to do to bring sandboxing to other languages.  Finally, we end with a vision of
what software development could look like with broader first-class support for
sandboxing.

# The road to RLBox: library sandboxing in Firefox

Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. Since these libraries have been
a significant source of vulnerabilities in the browser (e.g., most of the
browser bugs found by Sys this year were in third-party libraries
[[**BSE20**][BSE20]]), by retrofitting Firefox to sandbox libraries we can
minimize the damage due to library bugs (e.g., like the libvorbis bug at
Pwn2Own 2018 to compromise Firefox).

We started this project roughly two years thinking the hardest part of
sandboxing libraries is adopting a software-based isolation (SFI)
toolkit---Google's NativeClient (NaCl) at the time---for library sandboxing .
(NaCl is designed for sandboxing programs, not libraries.) This turned out be
the easy part and, since then, WebAssembly toolkits---in particular, the Lucet
WebAssembly compiler---has made this even easier (see
[[**NGLSS19**][NGLSS19]]).

The hard part was the _last mile_, retrofitting Firefox to account for the
now-untrusted libraries.  Firefox was written assuming libraries are trusted.
To benefit from sandboxing, we had to change our threat model to assume
libraries are untrusted, and modify the browser-library interface accordingly.
In particular, we had to sanitize all data and regulate control flow between
sandboxed libraries and the browser to prevent libraries from breaking out of
their sandbox. Doing this manually was prone to error and onerous.

**Traps and pitfalls**
To illustrate the kinds of security challenges  we encountered, consider, for
instance, refactoring the `fill_input_buffer` JPEG decoder function in Firefox.
This function is called by the libjpeg library whenever it needs more bytes
from Firefox. Additionally, Firefox must save the currently unused input bytes
held by libjpeg to an internal back buffer and resend this libjpeg along with
additional input.

```cpp
 1: void fill_input_buffer (j_decompress_ptr jd) {
 2:   struct jpeg_source_mgr* src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data;
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte, src->bytes_in_buffer);
18:   ...
19: }
````

When sandboxing libjpeg, we need to refactor this code to account for the
now-untrusted library boundary. Among other things, we must:

- Sanitize `jd`, otherwise the read of `jd->src` on line 2 becomes an
  arbitrary-read gadget.
- Sanitize `src`, otherwise the write to `src->next_input_byte` on line 5
  becomes an arbitrary-write gadget and the `memmove()` on line 16 becomes an
  arbitrary read.
- Sanitize `decoder` to ensure it points to a valid Firefox `nsJPEGDecoder`
  object, otherwise invoking a virtual method on it will hijack control flow.
- Sanitize the nested pointer `mInfo.err` on line 10 prior to dereferencing.
- Sanitize the pointer `decoder->mBackBuffer + decoder->mBackBufferLen` used on
  the destination address to `memmove()` on line 16.
- Swizzle pointers like `mInfo.err` and `decoder->mBackBuffer`, i.e., translate
  the pointers to account for the potentially different machine model of the
  sandbox. Both NaCl and WebAssembly have different pointer representations.
- Ensure that multiple threads can't invoke the callback on the same image,
  otherwise we have data race that result in a use-after-free vulnerability.

Missing any of these checks---and these are only a subset of the kinds of
checks we identified in [[**NDG+20**][NDG+20]]---allows a compromised library
to carry out _confused deputy_ attacks, i.e., abuse the application code and
its privilege to essentially break out of the sandbox.  Unfortunately, getting
all the right checks in all the right places for the hundreds of Firefox
functions that interact with libjpeg is hard. Indeed, while migrating Firefox
to this model we made many mistakes---overlooking attack vectors and
discovering many bugs only after building RLBox to help detect them.

**Engineering effort**
Even if we could somehow get all checks right, the upfront engineering effort
of retrofitting the browser to sandbox any library as such is huge: We have to
retrofit all library calls, adjust data structures to account for machine model
differences between the application and sandbox (a common issue with SFI
toolchains), marshal data to and from the sandbox, etc. Only then can we run
tests to ensure our retrofitting didn't break the browser.  Finally, since
Firefox runs on many platforms---including platforms not yet supported by SFI
toolkits like NaCl and Wasm---we have to do this alongside the existing code
that used the library unsandboxed, using the C preprocessor to select between
the old code and the new code. We tried this approach. But the patches become
so complicated and unwieldy, we couldn't image anybody maintaining this code.
We built RLBox and started anew.

# The RLBox framework

RLBox is a C++ library designed to make it easier for developers to retrofit
application to securely use sandboxed libraries.  RLBox does this by making
data and control flow at the application-sandbox boundary explicit---at the
type level--and by providing APIs to both mediate these flows and enforce
security checks across the trust boundary.

RLBox mediates data flow using _tainted types_---type wrappers used to
demarkcate data originating from the sandbox.  We use tainted values to ensure
that application code cannot use sandboxed data unsafely.  For example, while
application code can add two `tainted<int>` (to produce another
`tainted<int>`), it cannot branch on such values or use them as indexes into an
array. Instead, the application must validate before it can use it.

RLBox mediates control flow by providing APIs for invoking sandboxed functions,
registering host functions as callbacks---to allow the sandbox to call into the
application---and more generally exchange data between the sandbox and
application.  For example, application must use `sandbox_invoke(sbx_fn,
args...)` to invoke functions in the sandbox; sandboxed functions cannot be
called directly.  Similarly, sandboxed code cannot call into the application
aribrarily; instead, the application must register callback functions using the
`sandbox_callback(app_fn)` API. These APIs are also key to data flow safety:
They impose a strict tainted type discipline, requiring all return values of
sandboxed functions and all callback arguments to be tainted.

This tained type-driven approach addresses the challenges we outlined above:

- **Security:** RLBox eliminates most traps and pitfalls by turning unsafe
  control- and data-flows into type errors and, in some cases, by performing
  automatic security checks.  For example, RLBox automatically sanitizes
  sandbox-supplied (tainted) pointers to ensure they point sandbox memory,
  swizzles pointers that cross the trust boundary, and statically identifies
  locations where tainted data must be validated before use.

- **Engineering effort:** Compile-time type errors guide the developer through
  the process of migrating a library into a sandbox. Each compile error points
  to the next required code change---e.g., data that needs to be validated
  before use, or control transfer code that needs to be changed to use the
  RLBox APIs.  This allows developers to incrementally port application code
  one line at a time, instead of wholesale.

  By forcing all control and data flow to go though explicit APIs, RLBox
  automatically handles ABI differences in shared datastructures and makes it
  easy for developers to switch the underlying isolation mechanisms. This, in
  turn, makes patches simpler: The code interfacing with the library doesn't
  have to change across platforms (e.g., on platform where NaCl or WebAssembly
  is not supported we just use the noop-sandbox).

We ellaborate on both below, and discuss new uses cases this framework enables.

## Automating security checks to eliminate confused deputy attacks

For example, if we consider the example shown earlier, RLBox's compiler errors
would require us to mark the parameters jd, and the jpeg data structure mInfo as
tainted. After this, RLBox would be able to automate insertion of several
checks, such as the pointer bounds checks. RLBox then use compiler errors to
indicate the need for some remaining checks; specifically that the parameters to
memmove must be sanitized before use. We show the same example modified to use
RLBox below.

```cpp
 1: void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
 2:   tainted<jpeg_source_mgr*> src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data.copy_and_verify(...);
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte.copy_and_verify(...),
18:          src->bytes_in_buffer.copy_and_verify(...));
19:   ...
20: }
````

Note that it is still up to the user to figure out how to check the parameters
to memove are safe---i.e. the user has to write safety checks in the three calls
to verify above. In this case, the following checks are required for the decoder.

- The `decoder` being used is a valid object referring to one of the currently
  active image decoders.
- The decoder not being used by a concurrent thread (to prevent race conditions).

To validate the parameters to `memmove`, the following checks must be performed

- The field `next_input_byte` is a pointer within sandbox memory
- The value of `next_input_byte _+ bytes_in_buffer` is also a pointer
  sandbox memory
- The value of `bytes_in_buffer` would not overflow the destination buffer.

<!-- Not leading with the below text for this fix as rlbox only allows
memcpy(tainted dest, tainted src)
OR
memcpy(tainted dest, void* src)

but not
memcpy(void* dest, tainted src)

as I think this may allow bad coding patterns which accidentally smuggles
tainted data

-->
Additionally, to further simplify such code, RLBox also provides overloads of
standard APIs such as memcpy, strcpy etc. that accept tainted values and can be
used to automate such checks.

## Minimizing sandboxing engineering effort

While we have mostly focussed on the security features of RLBox so far, RLBox
has several features designed to greatly reduce engineering effort -- this is
extremely important in practice. Without these features, modifying application
code for correct and safe use sandboxed library can quickly become tedious and
error-prone. We present just two of the main challenges below.

First, SFI toolchains such as NaCl or Wasm have a different ABI than application
code. Specifically, Wasm and NaCl use a 32-bit machine model (LP32) for
performance i.e. the size of "long" and a "void*" in C code is 32-bits. Thus
sharing data-structures between application code and libraries is not
straightforward. Additionally, pointers in these toolchains use a different
format---pointers are stored as relative offsets from the base of the sandbox
heap for performance. Thus any datastructure that is exchanged between the
application and library must account for size differences as well as convert or
"swizzle" the pointer representations appropriately.

Next, libraries are often tightly coupled to application code. For instance,
when sandboxing the use of libjpeg in Firefox, we found that there are 25
different API calls, 5 callbacks and many shared data structures between Firefox
and libjpeg. However, sandboxing mechanisms often require code to use the
sanctioned means of performing function calls and callbacks---the springboards
and trampolines. We cannot reasonably expect application developers to migrate
all interactions with sandboxed library to the trampolines and springboards in a
single step.

RLBox addresses both of these challenges through a combination of automation and
compiler driven feedback. We discuss how RLBox addresses both of these
challenges in more detail below.

### Automatically bridging ABI incompatibilities

RLBox automatically bridges ABI differences by leveraging the type system. In
particular, RLBox uses two types---tainted<T> and tainted_volatile<T> to
automate ABI conversions. The tainted type represents any numeric data
influenced by the sandbox as well as pointers held by the application that refer
to memory inside the sandbox; the tainted_volatile<T> type is used for any data
stored in sandbox memory i.e. it can be directly modified by sandbox code. 
We note that tainted_volatile<T>  is an internal detail of RLBox and is never
exposed to users of RLBox.

This simple division allows RLBox to automatically apply ABI conversions, adjust
field offsets in structs, correct pointer arithmetic, swizzle pointers by
leveraging the type of data being operated on. These types even automatically
bounds check pointers appropriately as they are dereferenced. To demonstrate the
benefits of this automation, we show how one line of code from the previous
example must be changed to account for ABI differences, with and without RLBox.

Consider the following line of code from the previous example of
`fill_input_buffer`.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line _without_ RLBox's automatic ABI conversions and
security checks, the resulting code would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err");
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox lets you write the above exactly as it originally was
written i.e.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

### Incremental migration

RLBox allows us to migrate application code to use the RLBox API one line at a
time. Between each change, the application can be compiled and run as before.
While the details of our approach is explained in detail in our paper
[[**NDG+20**][NDG+20]], the key parts of RLBox that allow for is the concept of
escape hatches---techniques that let us disable RLBox's checks for a piece of
code.

RLBox offers two important escape hatches.

1) The UNSAFE_unverified API may be used on any tainted data to remove the
   tainted wrapper. This allows the application code to disable tainting when
   data must be passed to code that cannot handle tainted data. However, as the
   API name indicates, the use of this API would not enforce the required
   security checks, and is to be used only in the context of migrating code.
   After migration is complete, calls to UNSAFE_unverified APIs must be removed
   or replaced with validator functions that sanitize the given data.

2) The RLBox noop sandbox allows the application code to simply disable the
   underlying isolation mechanism. Instead, this option simply redirects
   function calls back to the application but wraps data as if it were received
   from a sandboxed library. This allows us to test the data validation without
   having to actually use a sandboxed library. Despite its simplicity, the noop
   sandbox plays a very important role! Since, sandboxing mechanisms such as
   WebAssembly have a different ABI, incremental porting cannot be supported as
   automatic ABI conversions are not possible when escape hatches such as
   UNSAFE_unverified were used. Instead during incremental migration, developers
   must use the noop sandbox and switch to Wasm enforcement once this migration
   is complete.

While RLBox's features were designed with the above use cases in mind, we also
discovered several unexpected practical benefits as we incorporated this more
in production code. We discuss these below.

First the incremental porting greatly simplifies the code review process. For
instance, we could commit and get reviews for partial migrations to the RLBox
API, especially since the Firefox browser continued to build and run as before.
Additionally, in the initial migration we simply omitted the validators for use
of UNSAFE_unverified APIs. This allowed to test and deploy the partial migration
on Firefox nightly builds. We then included the data validators in a separate
code review with additional security reviews as part of this change.

Next we discovered that the noop sandbox is critical for downstream projects.
When speaking with developers of the Tor browser, a downstream fork of the
Firefox browser that allows anonymous browsing in the web, we found that Tor was
open to sandbox more libraries than Firefox despite additional performance
overhead due to their higher security requirements. However, the burden of
maintaining a large fork of Firefox with sandboxed libraries was not an
acceptable option. Instead, the RLBox API provides a simple option; Tor
developers could migrate code to use the RLBox API and contribute this upstream
using the noop sandbox---a change that has little to no overhead (< 1%). The
downstream Tor configuration could however specify an isolation mechanism that
provides enforcement.

Indeed this flexibility in switching between memory isolation also allows easy
experimentation with many new hardware features. We discuss this next.

## Leveraging advances in SFI and hardware isolation

As discussed RLBox's design allows it to easily switch between different
sandboxing mechanisms. We have explored several in [[**NDG+20**][NDG+20]].
However, many more mechanisms exist each offering different
performance/compatibility/security trade-offs. A particular area of interest is
the growth in native hardware based support for sandboxing.

For example, consider Intel's Memory Protection Key features (MPK). This allows
very efficient sandboxing of components, and is largely compatible and easy to
use with existing code as shown in !!! ERIM !!!. Due to RLBox, design, it would
straightforward to implement RLBox support to use MPK as the isolation
mechanism.

Another interesting example is CHERI---an approach to supporting a capability
based model for architectures such as ARM, RISC-V etc. Here, the hardware
enforcement would include and apply bounds checks for all pointers and pointer
dereferences. However, this feature does expand the size of pointers, so it may
not be easy to deploy for all applications especially if the increased pointer
size introduces incompatibilities. Furthermore, it would not be easy to apply
CHERI to just the portion of the code that is compatible; this would make any
data-structures from this portion of code have a different ABI with the rest of
the application. However, since RLBox can automatically adjust for ABI
differences, applications can straightforwardly use CHERI to secure parts of the
application that are compatible with CHERI.

<!-- Should we include the DONKY example for RISC-V? Not sure if that is purely
an academic proposal or was something that would potentially be implemented. If
it is going to be implemented, we should totally mention this.  -->

# Language support for Sandboxing with Tainted Types

Though we implemented RLBox in C++ to sandbox C libraries, we believe the
underlying principles translate to other languages. Going even further, we
propose first class support for RLBox in languages and their tooling. Not only
would this make the use of tainted type more seamless, it would allow developers
to sandbox dependencies as they first import them into their project.

## RLBox's use of language features

To understand how to bring RLBox to other languages, we need to first
understand which C++ features RLBox relies on. Primarily, RLBox uses tainted
types (implemented via C++ generics) and leverages compiler type checking to
enforce security properties. RLBox also permits safe operations on tainted
types under certain constraints by taking advantage of operator overloading,
and enforces constraints on these operations using C++ metaprogramming
techniques.

Many other languages include features which can be used to implement the same
general RLBox principles. For instance, many statically-typed languages offer
some form of generics or templates which could be used to implement RLBox's
tainted and tainted_volatile types. A notable exception here is
C---supporting RLBox in C would require some tool for code generation.
Similarly, many languages allow operator overloading, which RLBox uses to
provide safe operations on tainted types while preserving the original
syntax of the language. (For instance, in C++, RLBox allows dereferencing
a tainted<int*> via the natural '->' and '*' operators, but with automatically
inserted bounds checks.)

Frameworks like RLBox can also be used to enforce security in dynamically
typed languages like JavaScript. However, without compiler assistance, RLBox
cannot provide helpful compile-time assistance, which is especially important
during incremental porting. Instead, the errors would manifest as runtime
errors. Thus, while the usability of RLBox would be reduced, the security
guarantees would be the same.

This is just the beginning! We envision a future where RLBox could leverage
many additional language features as well. For instance, RLBox could take
advantage of Rust's affine types to automatically prevent
time-of-check-time-of-use attacks and double fetch attacks. RLBox could also
leverage contracts --- as recently proposed for C++, or for Wasm's interface
types --- to automatically validate tainted data prior to use.

<!-- RLBox currently requires extra user specification (in the form of macros)
to fully support structs. However, C++ metaclasses and reflection support will
allow RLBox to support this automatically.-->

# Making Sandboxing a First Class Part of the Developer Experience

While RLBox has been a boon for our work in Firefox, it's just a starting
point.  Our hope is that library sandboxing will become a first class activity
in future development environments, and that RLBox's capabilties will
ultimately be subsumed by standard parts of tommorows languages, toolchains and
package managers. We believe in many cases such support could allow the use of
sandboxed libraries with a level of ease comperable to the use of unsandboxed
libraries today.

Libary sandboxing support in language module system or package manager could
allow users to seamlessly choose to sandbox libraries when importing
dependencies.  

Packages could make explicit as part of their specification what
privileges they need to carry out their task, and developers could then choose
if and how to grant these privileges as part of importing a package.

Integrated support for applying tainted types to values produced by sandboxed
libraries could faciltate safe library use, and a natural syntax for invoking
sandboxed functions ala. RLBox could make the transition to using sandboxed
versions of libraries natural and seemless. 

Much of the work of writing validators for tainted types could be mitigated by
distributed validators as part of a sandboxed library. While this would entail
placing trust in the author of the validors, because they are a relatively
small amount of code, auditing them could be quite tractable.


XXX I don't understand the typescript thing.
Language tooling
could automatically adjust its build system to appropriately switch to a
sandboxing compiler for libraries which the user wants to sandbox. The
language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing
even more seamless for users, resulting in greater security in the greater
software ecosystem.

All mainstream programming languages support a foreign function interface (FFI)
to invoke function in libraries written in other languages, particularly C, and
many popular languages such as Python, Ruby, and Javascript (ala Node.js) make
extensive use or native code in their standard libraries and package
ecosystems. First class support for sandboxing native code as part of FFI
interfaces, which has been explored in multiple research projects,
!!!tocite{robusta, sandcrust, some node thing?, lookup language sandboxes}!!!!.
could not only benefit assurnace, but also provide significant
benefits for debugging as native code that violates invariants of the language
runtime lead to notoriously difficult bugs.

Rust is a particularly compelling language ecosystem for an approach like
RLBox. Rust's raison de etre (XXX fix punctuation) is safety, and it finds use
in many settings where assurance is a paramount, thus the ability to more
safely use native code fits in well with the overall Rust vision.

At the language and tooling level, Rust is well suited to our approach.  Its
support for generics and operator overloading via typeclasses naturally lends
itself to our approach. It's rich macro system and affine types could also
support features not possible in C++ RLBox; such as automatic struct support
(XXX whats this) and time-of-check-time-of-use prevention. 

The presence of a powerful common build systems and package manager i.e. Cargo,
also lends itself smooth support for library sandboxing.  Extending Cargo with
an additional flag in the Cargo.toml file, to to indicate when a dependency
should be sandboxed could be quite straightforward.

<!--
, and automatically augment function return values with
tainted types could be quite natural. 

Of course developers would still responsible for modifying their code to add
validators where needed, however this would encourage developers to consider
sandboxing as an important tool for dependencies.

-->


# Conclusions

- library sandboxing can be a pratical thing in production systems, currently shipping in firefox
- RLbox shows how to overcome security and software engineering challenges, similar ideas can
be applied in other languges

- First class support for this in other parts of the tool chain i.e. package manager can move
us closer to world were sandboxed libraries not significantly harder to use than standard libraries.





# References

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285



<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>

