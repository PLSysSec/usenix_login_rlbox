<meta charset="utf-8"><!-- -*- markdown -*- -->

-- Title: Lowering the barrier to in-process sandboxing

# Introduction

Modern software makes heavy use of third-party libraries. While this is
critical for developer productivity, it is also a security nightmare. Third
party libraries, today, are completely trusted. Unfortunately, this means that
bugs in any library can be easily exploited to compromise the entire
application. Further, attacks on software supply chains are becoming more
prevalent: attackers are compromising (and sometimes buying) the accounts of
software maintainers to slip backdoored code into popular libraries.

There is a practical alternative to today's trust-everything model: we can
enforce least privilege by sandboxing libraries. Thus, minimizing the damage
inflicted by buggy or malicious libraries.  While this may sound radical at
first glance, in our experience it is often not a significant departure from
how we use libraries today.

As a result of basic principles of modularity and good interface design, most
libraries do not require unfettered access to the processes entire address
space. They also require only a limited set of OS privileges to accomplish their
task. Together these properties make libraries especially well suited to
running in de-privileged and memory isolated contexts.

For example, image decoders like libjpeg and libpng don't need access to
anything but the image buffers they operate on, OpenSSL doesn't need access to
anything but the socket it's reading from and the bytestream it's writing the
decrypted HTTP stream to, and spell checkers like Hunspell don't need access to
anything but dictionary files and the string it's spell checking.

These are just a few examples, however, we believe other examples abound.
Unfortunately, library sandboxing has suffered from a chicken and egg problem.
Without practical tools for securely sandboxing libraries with minimal
performance overhead and engineering effort, developers and security engineers
are not looking for these opportunities.

We believe it is time for a shift in this perspective.  Over the past two years
we have worked with a team at Mozilla to migrate Firefox to a model where a
variety of different third party libraries run sandboxed. This new approach has
been shipping in Firefox since XXX. Our experience suggests that once their is
sufficient tooling support that engineers can easily sandbox libraries, they
become increasingly comfortable with and excited by the opportunities this
offers.

For example, while we began with third party font shaping libraries, now
Firefox developers and security engineers are using RLBox for media decoding,
spell checking, even speech synthesis. Similar opportunities exist in many
other application domains. For example, secure messaging apps (e.g., Signal,
WhatsApp, and iMessage), servers and runtimes (e.g., Apache and Node.js), and
enterprise tools (e.g., Zoom, Slack, and VS Code) also rely on third party
libraries for various tasks---from media rendering, to parsing network
protocols like HTTP, image processing (e.g., to blur faces), spell checking,
and automated text completion. 

Recent advances in compiler and processor architecture space have made
efficient in-process isolation increasingly practical in a wide range of use
cases.  But, to make library sandboxing a goto tool in more software
engineering environments, the missing element has been a common framework that
makes it easy to sandbox libraries (1) _securely_, to correctly enforce a
secure interface between the untrusted library and the application, (2)
_effectively_, to minimize the engineering effort required to sandbox a
library, and (3) _modularly_, to support different isolation techniques---from
NaCl, to WebAssembly, and hardware isolation mechanisms like Intel's Memory
Protection Key (MPK).

Our own experience sandboxing libraries in Firefox reflects this. Our initial
attempts to manually sandbox third party libraries were labor intensive, and
very prone to security bugs. In contrast, once we developed the RLBox framework
[[**NDG+20**][NDG+20]] the incremental work to sandbox new libraries became
minimal, and more opportunities to sandbox additional parts of the application
became apparent. We think other applications can benefit from RLBox and as an
example, in [[**NDG+20**][NDG+20]], we demonstrated its use sandboxing
third-party Apache and native Node.js modules.

In the rest of this article we describe the experience that led to RLBox, then
we describe how RLBox works, how it leverages the C++ type systems to make
sandboxing practical, and how our type-driven approach can be used in other
domains (e.g., trusted execution environments).  Then we outline what we need
to do to bring sandboxing to other languages.  Finally, we end with a vision of
what software development could look like with broader first-class support for
sandboxing.

# Library sandboxing in Firefox with RLBox

Firefox, like other browsers, relies on dozens of third-party libraries to
decode audio, images, fonts, and other content. Since these libraries have been
a significant source of vulnerabilities in the browser (e.g., most of the
browser bugs found by Sys this year were in third-party libraries
[[**BSE20**][BSE20]]), by retrofitting Firefox to sandbox libraries we can
minimize the damage due to library bugs (e.g., like the libvorbis bug at
Pwn2Own 2018 to compromise Firefox).

We started this project roughly two years thinking the hardest part of
sandboxing libraries is adopting a software-based isolation (SFI)
toolkit---Google's NativeClient (NaCl) at the time---for library sandboxing .
(NaCl is designed for sandboxing programs, not libraries.) This turned out be
the easy part and, since then, WebAssembly toolkits---in particular, the Lucet
WebAssembly compiler---has made this even easier (see
[[**NGLSS19**][NGLSS19]]).

The hard part was the _last mile_, retrofitting Firefox to account for the
now-untrusted libraries.  Firefox was written assuming libraries are trusted.
To benefit from sandboxing, we had to change our threat model to assume
libraries are untrusted, and modify the browser-library interface accordingly.
In particular, we had to sanitize all data and regulate control flow between
sandboxed libraries and the browser to prevent libraries from breaking out of
their sandbox. Doing this manually was prone to error and onerous.

**Traps and pitfalls**
To illustrate the kinds of security challenges  we encountered, consider, for
instance, refactoring the `fill_input_buffer` JPEG decoder function in Firefox.
This function is called by the libjpeg library whenever it needs more bytes
from Firefox.

```cpp
 1: void fill_input_buffer (j_decompress_ptr jd) {
 2:   struct jpeg_source_mgr* src = jd->src;
 3:   nsJPEGDecoder* decoder = jd->client_data;
 4:   ...
 5:   src->next_input_byte = new_buffer;
 6:   ...
 7:   if (/* buffer is too small */) {
 8:     JOCTET* buf = (JOCTET*) realloc(...);
 9:     if (!buf) {
10:       decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
11:       ...
12:     }
13:     ...
14:   }
15:   ...
16:   memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
17:       src->next_input_byte, src->bytes_in_buffer);
18:   ...
19: }
````

When sandboxing libjpeg, we need to refactor this code to account for the
now-untrusted library boundary. Among other things, we must:

- Sanitize `jd`, otherwise the read of `jd->src` on line 2 becomes an
  arbitrary-read gadget.
- Sanitize `src`, otherwise the write to `src->next_input_byte` on line 5
  becomes an arbitrary-write gadget and the `memmove()` on line 16 becomes an
  arbitrary read.
- Sanitize `decoder` to ensure it points to a valid Firefox `nsJPEGDecoder`
  object, otherwise invoking a virtual method on it will hijack control flow.
- Sanitize the nested pointer `mInfo.err` on line 10 prior to dereferencing.
- Sanitize the pointer `decoder->mBackBuffer + decoder->mBackBufferLen` used on
  the destination address to `memmove()` on line 16.
- "Swizzle" pointers like `mInfo.err` and `decoder->mBackBuffer`, i.e., translate
  the pointers to account for the potentially different machine model of the
  sandbox. Both NaCl and WebAssembly have different pointer representations.
- Ensure that multiple threads can't invoke the callback on the same image,
  otherwise we have data race that result in a use-after-free vulnerability.

Missing any of these checks---and these are only a subset of the kinds of
checks we identified in [[**NDG+20**][NDG+20]]---allows a compromised library
to carry out _confused deputy_ attacks, i.e., abuse the application code and
its privilege to essentially break out of the sandbox.  Unfortunately, getting
all the right checks in all the right places for the hundreds of Firefox
functions that interact with libjpeg is hard. Indeed, while migrating Firefox
to this model we made many mistakes---overlooking attack vectors and
discovering many bugs only after building RLBox to help detect them.

**Engineering effort**
Even if we could somehow get all checks right, the upfront engineering effort
of retrofitting the browser to sandbox any library as such is huge: We have to
retrofit all library calls, adjust data structures to account for machine model
differences between the application and sandbox (a common issue with SFI
toolchains), marshal data to and from the sandbox, etc. Only then can we run
tests to ensure our retrofitting didn't break the browser.  Finally, since
Firefox runs on many platforms---including platforms not yet supported by SFI
toolkits like NaCl and Wasm---we have to do this alongside the existing code
that used the library unsandboxed, using the C preprocessor to select between
the old code and the new code. We tried this approach. But the patches become
so complicated and unwieldy, we couldn't image anybody maintaining this code.
We built RLBox and started anew.

# RLBox framework

# Why we need a common sandboxing Framework

RLBox is a pure C++ library that helps developers migrate, maintain code in
application to securely use sandboxed libraries. RLBox does this by providing
APIs to invoke sandboxed functions, permit callbacks into the host application
and more generally exchange data between the sandbox and application. These APIs
are built around tainted types---these are wrapper types used to mark data
received from the sandboxed library and impose a simple static information flow
control (IFC) discipline.

Importantly, RLBox was designed to precisely address the challenges presented in
the previous section, namely, minimizing the effort to securely and efficiently
sandbox libraries. The core of the challenge here is that the
applications-library boundary is tightly coupled and by default application code
is written assuming libraries are trusted. To benefit from sandboxing requires
changing our threat model to assume libraries are untrusted, and modify the
renderer-library interface accordingly (e.g, to sanitize untrusted inputs). In
the RLBox model, interactions with the sandboxed library must go through the
RLBox API. This allows RLBox to offer several useful features:

- Automate security checks: Pointer swizzle operations, bounds checks that
  ensure sandbox-supplied pointers point to sandbox memory, and identifying
  locations where tainted data from the sandbox must be validated before use is
  done automatically.
- Reduce engineering effort: The RLBox framework reduces effort by automatically
  handling all ABI differences in shared datastructures. Furthermore, RLBox
  allows developers to incrementally port application code one line at a time,
  such that the application compiles and runs with full functionality
  (passing all tests) between each step of porting.
- Evaluating performance tradeoffs: The RLBox framework allows easily switching
  between different sandboxing technologies with a single line of code and also
  provides built in benchmarking options to evaluate costs.

These features are central to RLBox's approach to making library sandboxing more
practical and we discuss these next.

## Eliminating confused deputy attacks

RLBox eliminates confused deputy attacks by mediating data and control flows at
the renderer-sandbox interface and enforce security checks across this trust
boundary. RLBox can do this by leveraging its type system and API design.

RLBox mediates data flow with tainted types that impose a simple static
information flow control (IFC) discipline. This ensures that sandbox data is
validated before any potentially unsafe use. It also prevents pointer leaks into
the sandbox that could break ASLR.

RLBox mediates control flow through a combination of tainted types and API
design. Tainting, for example, allows RLBox to prevent branching on tainted
values that have not been validated. API design, on the other hand, is used to
restrict control transfers between the renderer and sandbox. For instance, the
renderer must use sandbox_invoke() to invoke functions in the sandbox; any
callback into the renderer by the sandbox must first be registered by the
renderer using the sandbox_callback(callback_fn) API.

As a result, RLBox enforces security through two approaches. First, it automates
security checks such as bounds checking sandbox-supplied pointers to ensure they
point within sandbox memory as well as the identifying of locations where
tainted data must be validated. Second, RLBox uses compile-time type errors to
guide the developer through the process of migrating a library into a sandbox.
Each compile error points to the next required code change---e.g., data that
needs to be validated before use, or control transfer code that needs to be
changed to use RLBox APIs.

For example, if we consider the two examples shown earlier, RLBox's compiler
errors would require us to mark the parameters jd, and the jpeg data structure
mInfo as tainted. After this, RLBox would be able to automate all checks in the
first example, leaving the code as is. For the second example, above RLBox would
use compiler errors to indicate that parameters to memmove must be sanitized
before use as shown below.

```c++
void fill_input_buffer (rlbox_sandbox& sandbox, tainted<j_decompress_ptr> jd) {
  tainted<jpeg_source_mgr*> src = jd->src;
  ...
  memmove(decoder->mBackBuffer + decoder->mBackBufferLen,
    src->next_input_byte.verify(...), src->bytes_in_buffer.verify(...));
}
```

Note that it is still up to the user to figure out how to check the parameters
to memove are safe---i.e. the user has to write safety checks in the two
locations with "..." above. In this case, the following checks are required

- The field `next_input_byte` is a pointer within sandbox memory
- The value of `next_input_byte _+ bytes_in_buffer` is also a pointer within
  sandbox memory
- The value of `bytes_in_buffer` is would not overflow `mBackBufferLen`.

In practice, to simplify such code, RLBox also provides some overloads of
standard APIs such as memcpy, strcpy and more that accept tainted values and
automated these checks.

## Minimizing sandboxing engineering effort

While we have focussed on the security features of RLBox so far, RLBox has
several features designed to greatly reduce engineering effort -- in practice,
this is extremely important as without these features, migrating application
code can quickly become tedious and error-prone. Below we present some of the
challenges that prompted us S

For instance, SFI toolchains such as NaCl or Wasm have a different ABI than
application code. Wasm and NaCl use a 32-bit machine model (LP32) i.e. the size
of "long" and a "void*" in C code is 32-bits. Thus sharing data-structures
between application code and libraries is not straightforward. Additionally it
is not just differences in sizes, pointers in these toolchains have an
altogether different format---pointers are stores as relative offsets from the
base of the sandbox heap for performance. Thus any datastructure that are
exchanged between the application and library must account for size differences
as well as convert or "swizzle" the pointer representations appropriately.

The other challenge in using the sandboxed libraries is performing the code
changes required to migrate to using sandboxed libraries. Application may be
very tightly coupled with the library that is to be sandboxed. For instance,
when sandboxing the use of libjpeg in Firefox, we found that there are 25
different API calls, 5 callbacks and many shared data structures between Firefox
and libjpeg. We cannot reasonably expect application developers to migrate all
interactions with sandboxed library to the RLBox API in a single step.

RLBox addresses both of these challenges through a combination of automation and
compiler driven feedback. We discuss how RLBox addresses both of these
challenges in more detail below.

### Automatically bridging ABI incompatibilities

RLBox automatically bridges ABI differences by leveraging the type system. In
particular, RLBox uses two types---tainted<T> and tainted_volatile<T> to
automate ABI conversions. The tainted type represents any numeric data
influenced by the sandbox as well as pointers held by the application that refer
to memory inside the sandbox, while the tainted_volatile<T> type is used for any
data stored in sandbox memory i.e. can be modified by sandbox code.

This simple division allows RLBox to automatically apply ABI conversions, adjust
field offsets in structs, correct pointer arithmetic, swizzle pointers as
needed, and even automatically bounds check pointers appropriately as they are
dereferenced. The easiest way to demonstrate the importance of this automation.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

If we were to port this line with RLBox's automatic ABI conversions and security
checks, the resulting code would look as follows.

```c++
auto err_field = adjust_for_abi_get_minfo_field(decoder->minfo, "err");
auto err_field_swizzled = adjust_for_abi_convert_pointer(err_field);
auto msg_field = adjust_for_abi_get_err_field(*err_field_swizzled, "msg_code");
assert(in_sandbox_memory(msg_field)); // Bounds check
auto msg_field_swizzled = adjust_for_abi_convert_pointer(msg_field);
// assign the value
*msg_field_swizzled = adjust_for_abi(JERR_OUT_OF_MEMORY);
```

In contrast, RLBox lets you write the above exactly as it originally was
written i.e.

```c++
decoder->mInfo.err->msg_code = JERR_OUT_OF_MEMORY;
```

We note that tainted_volatile<T>  is an internal detail of RLBox
and is never exposed to users of RLBox.

### Incremental migration

RLBox allows us to migrate application code to use the RLBox API one line at a
time. Between each change, the application can be compiled and run as before.
While the precise approach is explained in detail in our paper, the key parts of
RLBox that allow for is the concept of escape hatches---techniques that let us
disable RLBox's checks for a piece of code.

RLBox offers two important escape hatches.

1) The UNSAFE_unverified API may be used on any tainted data to remove the
  tainted wrapper. This allows the application code to disable tainting of data
  when data must be passed to code that cannot handle tainted data. However, as
  the API name indicates, the use of this API would not enforce the required
  security checks, and is to be used only in the context of migrating code.
  After migration is complete, calls to UNSAFE_unverified APIs must be removed
  or replaced with validator functions that sanitize the given data.

2) The RLBox API allows the application code to choose the underlying isolation
  mechanism including a noop sandbox option. This option simply redirects
  function calls back to the application but wraps data as if it were received
  from a sandboxed library. This allows us to test the data validation without
  having to actually use a sandboxed library. But the noop sandbox plays an even
  more important role! Since, sandboxing mechanisms such as WebAssembly have a
  different ABI, incremental porting cannot be supported as there is no way to
  apply ABI conversions when escape hatches such as UNSAFE_unverified were used.
  Instead the incremental migration approach would be to use the noop sandbox
  during incremental migration and switch to Wasm enforcement once this
  migration is complete.


While these features were designed with the above use cases in mind, we also
discovered several unexpected practical benefits from the above feature set,
including their interactions after the publication as we incorporated this more
in production code. We discuss these below

First the incremental porting greatly simplifies the code review process. For
instance, we could commit and get reviews for partial migrations to the RLBox
API as this do not the Firefox browser continued to build and run as before.
Additionally, in the initial migration we simply omitted the validators for use
of UNSAFE_unverified APIs. This allowed to test and deploy the partial migration
on Firefox nightly builds. We then included the data validators in a separate
code review with additional security reviews as part of this change.

Next we discovered that the noop sandbox is critical for downstream projects.
When speaking with developers of the Tor browser, a downstream fork of the
Firefox browser that allows anonymous browsing in the web, we found that Tor was
open to sandbox more libraries than Firefox despite additional performance
overhead due to their higher security requirements. However, the burden of
maintaining a large fork of Firefox with sandboxed libraries was not an
acceptable option. Instead, the RLBox API provides a simple option; Tor
developers could migrate code to use the RLBox API but contribute upstream using
the noop sandbox. They could then switch the configuration in the Tor browser to
use an isolation mechanism that provides enforcement. Since using the noop
sandbox little to no overhead (< 1%), this is a reasonable option.

Indeed this flexibility in switching between memory isolation also allows easy
experimentation with many new hardware features. We discuss this next.

## Leveraging advances in SFI and hardware isolation

As discussed RLBox's design allows it to be agnostic to the memory isolation
technique. For example, consider Intel's Memory Protection Key features (MPK)
which allow very efficient sandboxing of components. It would straightforward to
implement RLBox support to use MPK as the isolation mechanism.

RLBox, also allows leveraging more complicated hardware security mechanisms. For
instance consider ARM Cheri, which is a hardware feature that converts pointers
into capabilities that apply bounds checks. Since this feature expands the size
of pointers it may not be easy to deploy for all applications especially if the
increased pointer size introduces incompatibilities. Furthermore it would not be
easy to apply this to just a portion of the code as any data-structures from
this portion of code would have ABI incompatibilities with the rest of the
application. However, since the RLBox can automatically adjust for ABI
differences, applications can straightforwardly use Cheri to secure a single
component in an application.

# Language support for Sandboxing with Tainted Types

Though we implemented RLBox in C++ to sandbox C libraries, we believe the
underlying principles translate to other languages. Going even further, we
propose first class support for RLBox in languages and their tooling. Not only
would this make the use of tainted type more seamless, it would allow developers
to sandbox dependencies as they first import them into their project.

## RLBox's use of language features

To understand how to bring RLBox to other languages, we need to first
understand which C++ features RLBox relies on. Primarily, RLBox uses tainted
types (implemented via C++ generics) and leverages compiler type checking to
enforce security properties. RLBox also permits safe operations on tainted
types under certain constraints by taking advantage of operator overloading,
and enforces constraints on these operations using C++ metaprogramming
techniques.

Many other languages include features which can be used to implement the same
general RLBox principles. For instance, many statically-typed languages offer
some form of generics or templates which could be used to implement RLBox's
tainted and tainted_volatile types. A notable exception here is
C---supporting RLBox in C would require some tool for code generation.
Similarly, many languages allow operator overloading, which RLBox uses to
provide safe operations on tainted types while preserving the original
syntax of the language. (For instance, in C++, RLBox allows dereferencing
a tainted<int*> via the natural '->' and '*' operators, but with automatically
inserted bounds checks.)

Frameworks like RLBox can also be used to enforce security in dynamically
typed languages like JavaScript. However, without compiler assistance, RLBox
cannot provide helpful compile-time assistance, which is especially important
during incremental porting. Instead, the errors would manifest as runtime
errors. Thus, while the usability of RLBox would be reduced, the security
guarantees would be the same.

This is just the beginning! We envision a future where RLBox could leverage
many additional language features as well. For instance, RLBox could take
advantage of Rust's affine types to automatically prevent
time-of-check-time-of-use attacks and double fetch attacks. RLBox could also
leverage contracts --- as recently proposed for C++, or for Wasm's interface
types --- to automatically validate tainted data prior to use.

<!-- RLBox currently requires extra user specification (in the form of macros)
to fully support structs. However, C++ metaclasses and reflection support will
allow RLBox to support this automatically.-->

# Making Sandboxing a First Class Part of the Developer Experience

While RLBox has been a boon for our work in Firefox, it's just a starting
point.  Our hope is that library sandboxing will become a first class activity
in future development environments, and that RLBox's capabilties will
ultimately be subsumed by standard parts of tommorows languages, toolchains and
package managers. We believe in many cases such support could allow the use of
sandboxed libraries with a level of ease comperable to the use of unsandboxed
libraries today.

Libary sandboxing support in language module system or package manager could
allow users to seamlessly choose to sandbox libraries when importing
dependencies.  

Packages could make explicit as part of their specification what
privileges they need to carry out their task, and developers could then choose
if and how to grant these privileges as part of importing a package.

Integrated support for applying tainted types to values produced by sandboxed
libraries could faciltate safe library use, and a natural syntax for invoking
sandboxed functions ala. RLBox could make the transition to using sandboxed
versions of libraries natural and seemless. 

Much of the work of writing validators for tainted types could be mitigated by
distributed validators as part of a sandboxed library. While this would entail
placing trust in the author of the validors, because they are a relatively
small amount of code, auditing them could be quite tractable.


XXX I don't understand the typescript thing.
Language tooling
could automatically adjust its build system to appropriately switch to a
sandboxing compiler for libraries which the user wants to sandbox. The
language could potentially even automatically pull in contract definitions
for each library's interface, using a system similar to what we see today for
TypeScript. In short, first-class support for RLBox could make sandboxing
even more seamless for users, resulting in greater security in the greater
software ecosystem.

All mainstream programming languages support a foreign function interface (FFI)
to invoke function in libraries written in other languages, particularly C, and
many popular languages such as Python, Ruby, and Javascript (ala Node.js) make
extensive use or native code in their standard libraries and package
ecosystems. First class support for sandboxing native code as part of FFI
interfaces, which has been explored in multiple research projects,
!!!tocite{robusta, sandcrust, some node thing?, lookup language sandboxes}!!!!.
could not only benefit assurnace, but also provide significant
benefits for debugging as native code that violates invariants of the language
runtime lead to notoriously difficult bugs.

Rust is a particularly compelling language ecosystem for an approach like
RLBox. Rust's raison de etre (XXX fix punctuation) is safety, and it finds use
in many settings where assurance is a paramount, thus the ability to more
safely use native code fits in well with the overall Rust vision.

At the language and tooling level, Rust is well suited to our approach.  Its
support for generics and operator overloading via typeclasses naturally lends
itself to our approach. It's rich macro system and affine types could also
support features not possible in C++ RLBox; such as automatic struct support
(XXX whats this) and time-of-check-time-of-use prevention. 

The presence of a powerful common build systems and package manager i.e. Cargo,
also lends itself smooth support for library sandboxing.  Extending Cargo with
an additional flag in the Cargo.toml file, to to indicate when a dependency
should be sandboxed could be quite straightforward.

<!--
, and automatically augment function return values with
tainted types could be quite natural. 

Of course developers would still responsible for modifying their code to add
validators where needed, however this would encourage developers to consider
sandboxing as an important tool for dependencies.

-->


# Conclusions

- library sandboxing can be a pratical thing in production systems, currently shipping in firefox
- RLbox shows how to overcome security and software engineering challenges, similar ideas can
be applied in other languges

- First class support for this in other parts of the tool chain i.e. package manager can move
us closer to world were sandboxed libraries not significantly harder to use than standard libraries.





# References

[**NDG+20**] S. Narayan, C. Disselkoen, T. Garfinkel, N. Froyd, E. Rahm, S. Lerner, H. Shacham, and D. Stefan. "[Retrofitting Fine Grain Isolation in the Firefox Renderer][NDG+20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[NDG+20]: https://www.usenix.org/conference/usenixsecurity20/presentation/narayan

[**BSE20**] F. Brown, D. Stefan, and D. Engler. "[Sys: a Static/Symbolic Tool for Finding Good Bugs in Good (Browser) Code][BSE20]". In S. Capkun and F. Roesner, eds., _Proceedings of USENIX Security 2020_. USENIX, Aug. 2020.
[BSE20]: https://www.usenix.org/conference/usenixsecurity20/presentation/brown

[**NGLSS19**] S. Narayan, T. Garfinkel, S. Lerner, H. Shacham, and D. Stefan.  "[Gobi: WebAssembly as a Practical Path to Library Sandboxing][NGLSS19]".  arXiv:1912.02285, Dec. 2019.
[NGLSS19]: https://arxiv.org/abs/1912.02285



<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>
<script src="markdeep.min.js"></script>
<script>
  window.alreadyProcessedMarkdeep || (document.body.style.visibility="visible");
  markdeepOptions= {tocStyle: 'long', sortScheduleLists: false };
</script>

